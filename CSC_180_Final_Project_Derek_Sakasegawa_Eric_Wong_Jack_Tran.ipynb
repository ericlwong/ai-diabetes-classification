{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwSebI6F5uTM"
   },
   "source": [
    "# CSC 180 Final Project: Classifying Diabetes Risk Among Patient Questionnaires\n",
    "### Spring 2021\n",
    "Derek Sakasegawa (219500607)  \n",
    "Eric Wong (219515297)  \n",
    "Jack Tran(219589865)  \n",
    "Dr. Chen  \n",
    "5/3/21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7hATrs_65ok"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "In this section, we will be loading the data which is filled with answers to a questionnaire by numerous patients. The answers provided by each patient will be used for training in our AI models to predict whether or not each patient is at risk of diabetes or not. Listed below are some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYS4DCCt64ue"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from sklearn import preprocessing\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from collections.abc import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn import metrics\n",
    "\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "    \n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) * (normalized_high - normalized_low) + normalized_low\n",
    "    \n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "    \n",
    "df = pd.read_csv(\"diabetes_data_upload.csv\", na_values=['NA','?'])\n",
    "\n",
    "df.columns = ['age','gender','polyuria', 'polydipsia', 'sudden_weight_loss', 'weakness', 'polyphagia', 'genital_thrush', 'visual_blurring', 'itching', \n",
    "              'irritability', 'delayed_healing', 'partial_paresis', 'muscle_stiffness', 'alopecia', 'obesity', 'class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3kp-MPvF8UXl"
   },
   "source": [
    "Here, we are showing off the data that is going to be used for training and testing in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "bwam9fsTAwIx",
    "outputId": "ceae3231-0e74-4ba4-fa70-d3c3a0527111"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>polyuria</th>\n",
       "      <th>polydipsia</th>\n",
       "      <th>sudden_weight_loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>polyphagia</th>\n",
       "      <th>genital_thrush</th>\n",
       "      <th>visual_blurring</th>\n",
       "      <th>itching</th>\n",
       "      <th>irritability</th>\n",
       "      <th>delayed_healing</th>\n",
       "      <th>partial_paresis</th>\n",
       "      <th>muscle_stiffness</th>\n",
       "      <th>alopecia</th>\n",
       "      <th>obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>48</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>58</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>42</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender polyuria  ... alopecia obesity     class\n",
       "0     40    Male       No  ...      Yes     Yes  Positive\n",
       "1     58    Male       No  ...      Yes      No  Positive\n",
       "2     41    Male      Yes  ...      Yes      No  Positive\n",
       "3     45    Male       No  ...       No      No  Positive\n",
       "4     60    Male      Yes  ...      Yes     Yes  Positive\n",
       "..   ...     ...      ...  ...      ...     ...       ...\n",
       "515   39  Female      Yes  ...       No      No  Positive\n",
       "516   48  Female      Yes  ...       No      No  Positive\n",
       "517   58  Female      Yes  ...       No     Yes  Positive\n",
       "518   32  Female       No  ...      Yes      No  Negative\n",
       "519   42    Male       No  ...       No      No  Negative\n",
       "\n",
       "[520 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8cdLDKi8b8n"
   },
   "source": [
    "We check here for any missing values in the dataset, so we can drop them if there are any. However, it appears there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkQQXy7JDLm9",
    "outputId": "4a519fd7-8d3a-43a7-a016-6d7ac845a508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "gender                0\n",
       "polyuria              0\n",
       "polydipsia            0\n",
       "sudden_weight_loss    0\n",
       "weakness              0\n",
       "polyphagia            0\n",
       "genital_thrush        0\n",
       "visual_blurring       0\n",
       "itching               0\n",
       "irritability          0\n",
       "delayed_healing       0\n",
       "partial_paresis       0\n",
       "muscle_stiffness      0\n",
       "alopecia              0\n",
       "obesity               0\n",
       "class                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhEksnPDBDds"
   },
   "source": [
    "## Encoding Categorical Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOfmW7LC8kBM"
   },
   "source": [
    "Now we encode each categorical feature to a numeric value as part of our preprocessing of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D8yjXHmrA-aa",
    "outputId": "d3cb122e-ca8c-4c5d-f84b-284da0f90b5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Negative', 'Positive'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_text_index(df, 'gender')\n",
    "encode_text_index(df, 'polyuria')\n",
    "encode_text_index(df, 'polydipsia')\n",
    "encode_text_index(df, 'sudden_weight_loss')\n",
    "encode_text_index(df, 'weakness')\n",
    "encode_text_index(df, 'polyphagia')\n",
    "encode_text_index(df, 'genital_thrush')\n",
    "encode_text_index(df, 'visual_blurring')\n",
    "encode_text_index(df, 'itching')\n",
    "encode_text_index(df, 'irritability')\n",
    "encode_text_index(df, 'delayed_healing')\n",
    "encode_text_index(df, 'partial_paresis')\n",
    "encode_text_index(df, 'muscle_stiffness')\n",
    "encode_text_index(df, 'alopecia')\n",
    "encode_text_index(df, 'obesity')\n",
    "encode_text_index(df, 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dGr7O5BE-Cnm"
   },
   "source": [
    "Here, we display the dataframe again to show that all attributes that had categorical values have been label encoded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "EpFI1JCqB6qb",
    "outputId": "69bcc982-8f21-4a72-bdf1-932ccc2e0a29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>polyuria</th>\n",
       "      <th>polydipsia</th>\n",
       "      <th>sudden_weight_loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>polyphagia</th>\n",
       "      <th>genital_thrush</th>\n",
       "      <th>visual_blurring</th>\n",
       "      <th>itching</th>\n",
       "      <th>irritability</th>\n",
       "      <th>delayed_healing</th>\n",
       "      <th>partial_paresis</th>\n",
       "      <th>muscle_stiffness</th>\n",
       "      <th>alopecia</th>\n",
       "      <th>obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  polyuria  ...  alopecia  obesity  class\n",
       "0     40       1         0  ...         1        1      1\n",
       "1     58       1         0  ...         1        0      1\n",
       "2     41       1         1  ...         1        0      1\n",
       "3     45       1         0  ...         0        0      1\n",
       "4     60       1         1  ...         1        1      1\n",
       "..   ...     ...       ...  ...       ...      ...    ...\n",
       "515   39       0         1  ...         0        0      1\n",
       "516   48       0         1  ...         0        0      1\n",
       "517   58       0         1  ...         0        1      1\n",
       "518   32       0         0  ...         1        0      0\n",
       "519   42       1         0  ...         0        0      0\n",
       "\n",
       "[520 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YmXykr-hD6aE"
   },
   "source": [
    "Next, we will show roughly about how many patients in the dataset were classified as nondiabetic and diabetic. Note: Nondiabetic was encoded to a value of 0 and diabetic was encoded to a value of 1.\n",
    "\n",
    "It can be seen that roughly 200 patients are classified as nondiabetic and 320 are classified as diabetic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "g1qN2ZzND0EL",
    "outputId": "71c80a1d-b0b1-4fb2-b68f-d435b56a1752"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>polyuria</th>\n",
       "      <th>polydipsia</th>\n",
       "      <th>sudden_weight_loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>polyphagia</th>\n",
       "      <th>genital_thrush</th>\n",
       "      <th>visual_blurring</th>\n",
       "      <th>itching</th>\n",
       "      <th>irritability</th>\n",
       "      <th>delayed_healing</th>\n",
       "      <th>partial_paresis</th>\n",
       "      <th>muscle_stiffness</th>\n",
       "      <th>alopecia</th>\n",
       "      <th>obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  polyuria  ...  alopecia  obesity  class\n",
       "200   40       1         0  ...         0        0      0\n",
       "201   28       1         0  ...         0        0      0\n",
       "202   37       1         0  ...         0        0      0\n",
       "203   34       1         0  ...         0        0      0\n",
       "204   30       1         0  ...         0        0      0\n",
       "..   ...     ...       ...  ...       ...      ...    ...\n",
       "510   67       1         0  ...         1        0      0\n",
       "511   66       1         0  ...         1        0      0\n",
       "512   43       1         0  ...         1        0      0\n",
       "518   32       0         0  ...         1        0      0\n",
       "519   42       1         0  ...         0        0      0\n",
       "\n",
       "[200 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']== 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "qhBVxz1yD2oY",
    "outputId": "d9803d5d-a356-404d-eaed-967662cde4e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>polyuria</th>\n",
       "      <th>polydipsia</th>\n",
       "      <th>sudden_weight_loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>polyphagia</th>\n",
       "      <th>genital_thrush</th>\n",
       "      <th>visual_blurring</th>\n",
       "      <th>itching</th>\n",
       "      <th>irritability</th>\n",
       "      <th>delayed_healing</th>\n",
       "      <th>partial_paresis</th>\n",
       "      <th>muscle_stiffness</th>\n",
       "      <th>alopecia</th>\n",
       "      <th>obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  polyuria  ...  alopecia  obesity  class\n",
       "0     40       1         0  ...         1        1      1\n",
       "1     58       1         0  ...         1        0      1\n",
       "2     41       1         1  ...         1        0      1\n",
       "3     45       1         0  ...         0        0      1\n",
       "4     60       1         1  ...         1        1      1\n",
       "..   ...     ...       ...  ...       ...      ...    ...\n",
       "513   62       0         1  ...         0        1      1\n",
       "514   54       0         1  ...         0        0      1\n",
       "515   39       0         1  ...         0        0      1\n",
       "516   48       0         1  ...         0        0      1\n",
       "517   58       0         1  ...         0        1      1\n",
       "\n",
       "[320 rows x 17 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['class']== 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ZXL8O3TfCjD"
   },
   "source": [
    "## Splitting Data into Test and Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23j5Q886-clj"
   },
   "source": [
    "Now we specify our inputs and outputs for the models and algorithms. Then they are split for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DhN81my8FQuL",
    "outputId": "53d8846d-c6b1-4017-dc12-b57bd71e0130"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((416, 16), (416,))"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdX8ZFzNfei1"
   },
   "source": [
    "##Random Forest Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OVDp9jIeUD3",
    "outputId": "81d6eb49-a4ce-45c2-808f-a91dd3e79442"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators = 100)\n",
    "rf_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blL_yC66eoDl"
   },
   "outputs": [],
   "source": [
    "predictions_rf = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-NK3K02flUd",
    "outputId": "3a0ee6d2-0571-4a63-8aa0-1bb752452ac3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy for Random Forest: 0.9903846153846154\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, predictions_rf)\n",
    "print(\"Final Accuracy for Random Forest: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bdbnb3fz-r15"
   },
   "source": [
    "Here, we are testing if model's performance in predicting 20 patients' condition after implementing the Random Forest algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "uh2cGywSjBmA",
    "outputId": "a126ab53-c6ac-434d-89f0-ad229412cc63"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted  Actual\n",
       "275          0       0\n",
       "93           1       1\n",
       "6            1       1\n",
       "167          1       1\n",
       "90           1       1\n",
       "513          1       1\n",
       "362          1       1\n",
       "228          0       0\n",
       "192          1       1\n",
       "482          0       0\n",
       "218          0       0\n",
       "180          1       1\n",
       "307          0       0\n",
       "508          0       0\n",
       "10           1       1\n",
       "381          1       1\n",
       "371          0       0\n",
       "30           1       1\n",
       "494          0       0\n",
       "137          1       1"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rf = pd.DataFrame({\"Predicted\": predictions_rf , \"Actual\": y_test})\n",
    "df_rf[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPn7-8E8jGwq",
    "outputId": "fc596d31-cd54-4e22-9eba-575b56001e3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[33  0]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "cm2 = metrics.confusion_matrix(y_test, predictions_rf)\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "ybWP2rObjJPT",
    "outputId": "22495b05-ba4a-45cc-cbdb-f9ffa96ffef8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = encode_text_index(df,\"class\")\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm2, classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yc_lDFD8j46L",
    "outputId": "82267839-7f8a-4f59-cb23-964684d70adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        33\n",
      "           1       1.00      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.99       104\n",
      "   macro avg       0.99      0.99      0.99       104\n",
      "weighted avg       0.99      0.99      0.99       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predictions_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nZeP-ulEhFFK"
   },
   "source": [
    "##KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "csFVOniMhEbc"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6xBeakIchS6-",
    "outputId": "2f85ea77-f3e5-4a2a-82b7-398c7ec9e624"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaCjG84ChVt1"
   },
   "outputs": [],
   "source": [
    "predictions_knn = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hvcmhNZnhYMW"
   },
   "outputs": [],
   "source": [
    "score1 = accuracy_score(y_test, predictions_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GzpvYgU7hapx",
    "outputId": "93f97bb3-7d9a-4c6c-cbb7-17181d02c6be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy for KNN: 0.875\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Accuracy for KNN: {}\".format(score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CfB9QRm_BFV"
   },
   "source": [
    "Here we are showing how well our model performed after implementing the KNN algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 669
    },
    "id": "Q76e9_bmhf0b",
    "outputId": "4b8b880d-c842-4e60-e88e-2f00c48cd97b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Actual Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted Values  Actual Values\n",
       "299                 1              1\n",
       "347                 1              0\n",
       "55                  0              1\n",
       "515                 1              1\n",
       "519                 0              0\n",
       "158                 1              1\n",
       "222                 0              0\n",
       "255                 1              1\n",
       "153                 1              1\n",
       "176                 1              1\n",
       "210                 0              0\n",
       "289                 0              0\n",
       "76                  1              1\n",
       "447                 1              1\n",
       "349                 0              0\n",
       "148                 0              1\n",
       "446                 1              1\n",
       "73                  1              1\n",
       "2                   1              1\n",
       "77                  1              1"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_knn = pd.DataFrame({\"Predicted Values\": predictions_knn , \"Actual Values\": y_test})\n",
    "df_knn[40:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIceHbulhy4O",
    "outputId": "bb336f5c-829e-465e-85d6-445a44824f40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  3]\n",
      " [10 61]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions_knn)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "2uBY-uaoh1xG",
    "outputId": "c7d3abca-6d68-43b9-dade-1d3274b67a81"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fmjns48ykFdA",
    "outputId": "6b89ec29-e964-4a4d-d610-c256851cb339"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82        33\n",
      "           1       0.95      0.86      0.90        71\n",
      "\n",
      "    accuracy                           0.88       104\n",
      "   macro avg       0.85      0.88      0.86       104\n",
      "weighted avg       0.89      0.88      0.88       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predictions_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aLUUBjinlK-R"
   },
   "source": [
    "## SVM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOzvoNlklShJ"
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel = \"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YMDqutNXlh4k",
    "outputId": "363dfc04-598f-43ba-abe3-6dcfd6ec44ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSPtT58lmiCa"
   },
   "outputs": [],
   "source": [
    "predictions_svm = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gm5p5eCcmpC-"
   },
   "outputs": [],
   "source": [
    "score1 = accuracy_score(y_test, predictions_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hDXYvSpgmvSf",
    "outputId": "1f7ee053-73cc-4ef1-e84e-ee686df0192d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy for SVM: 0.8942307692307693\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Accuracy for SVM: {}\".format(score1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJAFvvee_M_Z"
   },
   "source": [
    "Here we show how well our model performed after implementing the SVM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "jFVUIXV8mzgd",
    "outputId": "00977af3-23c5-483f-dfc5-37146305e6e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Values</th>\n",
       "      <th>Actual Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Predicted Values  Actual Values\n",
       "314                 0              0\n",
       "448                 1              1\n",
       "365                 1              1\n",
       "177                 1              1\n",
       "286                 0              0\n",
       "346                 1              1\n",
       "131                 1              1\n",
       "433                 1              1\n",
       "456                 1              1\n",
       "69                  1              1\n",
       "357                 1              0\n",
       "423                 1              1\n",
       "334                 0              0\n",
       "227                 0              0"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_svm = pd.DataFrame({\"Predicted Values\": predictions_svm , \"Actual Values\": y_test})\n",
    "df_svm[90:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRhudQMZm94K",
    "outputId": "4970fd79-ea13-4a6a-9c8f-f9dbeaf684ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28  5]\n",
      " [ 6 65]]\n"
     ]
    }
   ],
   "source": [
    "cm = metrics.confusion_matrix(y_test, predictions_svm)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "id": "8P_8GHTWnDTZ",
    "outputId": "c00f17cb-b8b2-4e7b-af46-985d2f1bf1fb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plot_confusion_matrix(cm, classes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihtMxkejfnob",
    "outputId": "55e9f35a-7ed8-4498-8305-a64766f9bd4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84        33\n",
      "           1       0.93      0.92      0.92        71\n",
      "\n",
      "    accuracy                           0.89       104\n",
      "   macro avg       0.88      0.88      0.88       104\n",
      "weighted avg       0.90      0.89      0.89       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predictions_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LQh7i6IrfTDE"
   },
   "source": [
    "##Fully Connected Neural Networks\n",
    "\n",
    "Now we split and train the data again for the building of our fully connected neural network models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvefXZIKcJtw",
    "outputId": "634a29a6-0d6a-469c-c3e4-da59ff147939"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((416, 16), (416, 2))"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = to_xy(df, 'class')\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huN1hU3iQwGY"
   },
   "source": [
    "## Fully Connected Neural Network Model #1 (Using relu & adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8YQ9tmCd2VL",
    "outputId": "a302d36f-927e-46b3-cd0a-4ee8524457cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 - 1s - loss: 4.8505 - val_loss: 1.0240\n",
      "Epoch 2/1000\n",
      "13/13 - 0s - loss: 1.1889 - val_loss: 1.0835\n",
      "Epoch 3/1000\n",
      "13/13 - 0s - loss: 0.9517 - val_loss: 1.0715\n",
      "Epoch 4/1000\n",
      "13/13 - 0s - loss: 0.8998 - val_loss: 0.9231\n",
      "Epoch 5/1000\n",
      "13/13 - 0s - loss: 0.8477 - val_loss: 0.9978\n",
      "Epoch 6/1000\n",
      "13/13 - 0s - loss: 0.8208 - val_loss: 0.8618\n",
      "Epoch 7/1000\n",
      "13/13 - 0s - loss: 0.8031 - val_loss: 0.8369\n",
      "Epoch 8/1000\n",
      "13/13 - 0s - loss: 0.7901 - val_loss: 0.8283\n",
      "Epoch 9/1000\n",
      "13/13 - 0s - loss: 0.7763 - val_loss: 0.8023\n",
      "Epoch 10/1000\n",
      "13/13 - 0s - loss: 0.7643 - val_loss: 0.7866\n",
      "Epoch 11/1000\n",
      "13/13 - 0s - loss: 0.7536 - val_loss: 0.7736\n",
      "Epoch 12/1000\n",
      "13/13 - 0s - loss: 0.7457 - val_loss: 0.7664\n",
      "Epoch 13/1000\n",
      "13/13 - 0s - loss: 0.7368 - val_loss: 0.7501\n",
      "Epoch 14/1000\n",
      "13/13 - 0s - loss: 0.7306 - val_loss: 0.7422\n",
      "Epoch 15/1000\n",
      "13/13 - 0s - loss: 0.7229 - val_loss: 0.7310\n",
      "Epoch 16/1000\n",
      "13/13 - 0s - loss: 0.7171 - val_loss: 0.7230\n",
      "Epoch 17/1000\n",
      "13/13 - 0s - loss: 0.7119 - val_loss: 0.7158\n",
      "Epoch 18/1000\n",
      "13/13 - 0s - loss: 0.7072 - val_loss: 0.7078\n",
      "Epoch 19/1000\n",
      "13/13 - 0s - loss: 0.7030 - val_loss: 0.7023\n",
      "Epoch 20/1000\n",
      "13/13 - 0s - loss: 0.6997 - val_loss: 0.6954\n",
      "Epoch 21/1000\n",
      "13/13 - 0s - loss: 0.6962 - val_loss: 0.6905\n",
      "Epoch 22/1000\n",
      "13/13 - 0s - loss: 0.6933 - val_loss: 0.6862\n",
      "Epoch 23/1000\n",
      "13/13 - 0s - loss: 0.6913 - val_loss: 0.6812\n",
      "Epoch 24/1000\n",
      "13/13 - 0s - loss: 0.6887 - val_loss: 0.6774\n",
      "Epoch 25/1000\n",
      "13/13 - 0s - loss: 0.6865 - val_loss: 0.6740\n",
      "Epoch 26/1000\n",
      "13/13 - 0s - loss: 0.6843 - val_loss: 0.6703\n",
      "Epoch 27/1000\n",
      "13/13 - 0s - loss: 0.6826 - val_loss: 0.6677\n",
      "Epoch 28/1000\n",
      "13/13 - 0s - loss: 0.6811 - val_loss: 0.6644\n",
      "Epoch 29/1000\n",
      "13/13 - 0s - loss: 0.6796 - val_loss: 0.6622\n",
      "Epoch 30/1000\n",
      "13/13 - 0s - loss: 0.6785 - val_loss: 0.6600\n",
      "Epoch 31/1000\n",
      "13/13 - 0s - loss: 0.6775 - val_loss: 0.6577\n",
      "Epoch 32/1000\n",
      "13/13 - 0s - loss: 0.6765 - val_loss: 0.6563\n",
      "Epoch 33/1000\n",
      "13/13 - 0s - loss: 0.6752 - val_loss: 0.6543\n",
      "Epoch 34/1000\n",
      "13/13 - 0s - loss: 0.6744 - val_loss: 0.6526\n",
      "Epoch 35/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6515\n",
      "Epoch 36/1000\n",
      "13/13 - 0s - loss: 0.6725 - val_loss: 0.6503\n",
      "Epoch 37/1000\n",
      "13/13 - 0s - loss: 0.6717 - val_loss: 0.6492\n",
      "Epoch 38/1000\n",
      "13/13 - 0s - loss: 0.6713 - val_loss: 0.6483\n",
      "Epoch 39/1000\n",
      "13/13 - 0s - loss: 0.6708 - val_loss: 0.6463\n",
      "Epoch 40/1000\n",
      "13/13 - 0s - loss: 0.6696 - val_loss: 0.6456\n",
      "Epoch 41/1000\n",
      "13/13 - 0s - loss: 0.6687 - val_loss: 0.6446\n",
      "Epoch 42/1000\n",
      "13/13 - 0s - loss: 0.6680 - val_loss: 0.6442\n",
      "Epoch 43/1000\n",
      "13/13 - 0s - loss: 0.6673 - val_loss: 0.6429\n",
      "Epoch 44/1000\n",
      "13/13 - 0s - loss: 0.6664 - val_loss: 0.6422\n",
      "Epoch 45/1000\n",
      "13/13 - 0s - loss: 0.6657 - val_loss: 0.6415\n",
      "Epoch 46/1000\n",
      "13/13 - 0s - loss: 0.6652 - val_loss: 0.6408\n",
      "Epoch 47/1000\n",
      "13/13 - 0s - loss: 0.6645 - val_loss: 0.6402\n",
      "Epoch 48/1000\n",
      "13/13 - 0s - loss: 0.6636 - val_loss: 0.6396\n",
      "Epoch 49/1000\n",
      "13/13 - 0s - loss: 0.6629 - val_loss: 0.6388\n",
      "Epoch 50/1000\n",
      "13/13 - 0s - loss: 0.6622 - val_loss: 0.6378\n",
      "Epoch 51/1000\n",
      "13/13 - 0s - loss: 0.6615 - val_loss: 0.6370\n",
      "Epoch 52/1000\n",
      "13/13 - 0s - loss: 0.6608 - val_loss: 0.6361\n",
      "Epoch 53/1000\n",
      "13/13 - 0s - loss: 0.6598 - val_loss: 0.6357\n",
      "Epoch 54/1000\n",
      "13/13 - 0s - loss: 0.6589 - val_loss: 0.6352\n",
      "Epoch 55/1000\n",
      "13/13 - 0s - loss: 0.6581 - val_loss: 0.6352\n",
      "Epoch 56/1000\n",
      "13/13 - 0s - loss: 0.6570 - val_loss: 0.6341\n",
      "Epoch 57/1000\n",
      "13/13 - 0s - loss: 0.6559 - val_loss: 0.6331\n",
      "Epoch 58/1000\n",
      "13/13 - 0s - loss: 0.6549 - val_loss: 0.6318\n",
      "Epoch 59/1000\n",
      "13/13 - 0s - loss: 0.6536 - val_loss: 0.6307\n",
      "Epoch 60/1000\n",
      "13/13 - 0s - loss: 0.6526 - val_loss: 0.6305\n",
      "Epoch 61/1000\n",
      "13/13 - 0s - loss: 0.6513 - val_loss: 0.6300\n",
      "Epoch 62/1000\n",
      "13/13 - 0s - loss: 0.6502 - val_loss: 0.6294\n",
      "Epoch 63/1000\n",
      "13/13 - 0s - loss: 0.6486 - val_loss: 0.6270\n",
      "Epoch 64/1000\n",
      "13/13 - 0s - loss: 0.6467 - val_loss: 0.6256\n",
      "Epoch 65/1000\n",
      "13/13 - 0s - loss: 0.6449 - val_loss: 0.6244\n",
      "Epoch 66/1000\n",
      "13/13 - 0s - loss: 0.6434 - val_loss: 0.6234\n",
      "Epoch 67/1000\n",
      "13/13 - 0s - loss: 0.6421 - val_loss: 0.6224\n",
      "Epoch 68/1000\n",
      "13/13 - 0s - loss: 0.6391 - val_loss: 0.6204\n",
      "Epoch 69/1000\n",
      "13/13 - 0s - loss: 0.6367 - val_loss: 0.6176\n",
      "Epoch 70/1000\n",
      "13/13 - 0s - loss: 0.6345 - val_loss: 0.6156\n",
      "Epoch 71/1000\n",
      "13/13 - 0s - loss: 0.6320 - val_loss: 0.6141\n",
      "Epoch 72/1000\n",
      "13/13 - 0s - loss: 0.6296 - val_loss: 0.6113\n",
      "Epoch 73/1000\n",
      "13/13 - 0s - loss: 0.6265 - val_loss: 0.6103\n",
      "Epoch 74/1000\n",
      "13/13 - 0s - loss: 0.6221 - val_loss: 0.6068\n",
      "Epoch 75/1000\n",
      "13/13 - 0s - loss: 0.6193 - val_loss: 0.6032\n",
      "Epoch 76/1000\n",
      "13/13 - 0s - loss: 0.6141 - val_loss: 0.5999\n",
      "Epoch 77/1000\n",
      "13/13 - 0s - loss: 0.6103 - val_loss: 0.5964\n",
      "Epoch 78/1000\n",
      "13/13 - 0s - loss: 0.6062 - val_loss: 0.5927\n",
      "Epoch 79/1000\n",
      "13/13 - 0s - loss: 0.6010 - val_loss: 0.5941\n",
      "Epoch 80/1000\n",
      "13/13 - 0s - loss: 0.5972 - val_loss: 0.5874\n",
      "Epoch 81/1000\n",
      "13/13 - 0s - loss: 0.5920 - val_loss: 0.5876\n",
      "Epoch 82/1000\n",
      "13/13 - 0s - loss: 0.5868 - val_loss: 0.5822\n",
      "Epoch 83/1000\n",
      "13/13 - 0s - loss: 0.5831 - val_loss: 0.5766\n",
      "Epoch 84/1000\n",
      "13/13 - 0s - loss: 0.5772 - val_loss: 0.5730\n",
      "Epoch 85/1000\n",
      "13/13 - 0s - loss: 0.5768 - val_loss: 0.5673\n",
      "Epoch 86/1000\n",
      "13/13 - 0s - loss: 0.5625 - val_loss: 0.5581\n",
      "Epoch 87/1000\n",
      "13/13 - 0s - loss: 0.5599 - val_loss: 0.5769\n",
      "Epoch 88/1000\n",
      "13/13 - 0s - loss: 0.5794 - val_loss: 0.5728\n",
      "Epoch 89/1000\n",
      "13/13 - 0s - loss: 0.5750 - val_loss: 0.6219\n",
      "Epoch 90/1000\n",
      "13/13 - 0s - loss: 0.5724 - val_loss: 0.5444\n",
      "Epoch 91/1000\n",
      "13/13 - 0s - loss: 0.5404 - val_loss: 0.5367\n",
      "Epoch 92/1000\n",
      "13/13 - 0s - loss: 0.5343 - val_loss: 0.5302\n",
      "Epoch 93/1000\n",
      "13/13 - 0s - loss: 0.5261 - val_loss: 0.5289\n",
      "Epoch 94/1000\n",
      "13/13 - 0s - loss: 2.3259 - val_loss: 2.9227\n",
      "Epoch 95/1000\n",
      "13/13 - 0s - loss: 3.5381 - val_loss: 2.9198\n",
      "Epoch 96/1000\n",
      "13/13 - 0s - loss: 3.5142 - val_loss: 2.8796\n",
      "Epoch 97/1000\n",
      "13/13 - 0s - loss: 3.4870 - val_loss: 2.8475\n",
      "Epoch 98/1000\n",
      "13/13 - 0s - loss: 3.4684 - val_loss: 2.8267\n",
      "Epoch 00098: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f652081b2d0>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Activation1\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='relu')) # Hidden 1     \n",
    "model.add(Dense(10, activation='relu')) # Hidden 2\n",
    "model.add(Dense(10)) \n",
    "model.add(Dense(10))\n",
    "model.add(Dense(1)) #1 Output neuron\n",
    "model.add(Dense(y.shape[1],activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BSXqG3a0kh0d",
    "outputId": "efa8b103-95ef-429c-98a4-9aa662f0fb77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6826923076923077\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PkBg_s6UQ9dL",
    "outputId": "8285c882-5695-452f-a102-35f11f9f2549"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.68      1.00      0.81        71\n",
      "\n",
      "    accuracy                           0.68       104\n",
      "   macro avg       0.34      0.50      0.41       104\n",
      "weighted avg       0.47      0.68      0.55       104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "knq1srYeQ_gw"
   },
   "source": [
    "## Fully Connected Neural Network Model #2 (Using sigmoid & adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYRqRHe7Qoeo",
    "outputId": "6658e46d-c8fd-4ddb-8530-d3dd98ce07e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 - 1s - loss: 0.6908 - val_loss: 0.6831\n",
      "Epoch 2/1000\n",
      "13/13 - 0s - loss: 0.6871 - val_loss: 0.6746\n",
      "Epoch 3/1000\n",
      "13/13 - 0s - loss: 0.6852 - val_loss: 0.6704\n",
      "Epoch 4/1000\n",
      "13/13 - 0s - loss: 0.6839 - val_loss: 0.6680\n",
      "Epoch 5/1000\n",
      "13/13 - 0s - loss: 0.6829 - val_loss: 0.6655\n",
      "Epoch 6/1000\n",
      "13/13 - 0s - loss: 0.6818 - val_loss: 0.6634\n",
      "Epoch 7/1000\n",
      "13/13 - 0s - loss: 0.6807 - val_loss: 0.6624\n",
      "Epoch 8/1000\n",
      "13/13 - 0s - loss: 0.6799 - val_loss: 0.6590\n",
      "Epoch 9/1000\n",
      "13/13 - 0s - loss: 0.6792 - val_loss: 0.6594\n",
      "Epoch 10/1000\n",
      "13/13 - 0s - loss: 0.6775 - val_loss: 0.6549\n",
      "Epoch 11/1000\n",
      "13/13 - 0s - loss: 0.6765 - val_loss: 0.6520\n",
      "Epoch 12/1000\n",
      "13/13 - 0s - loss: 0.6754 - val_loss: 0.6499\n",
      "Epoch 13/1000\n",
      "13/13 - 0s - loss: 0.6741 - val_loss: 0.6469\n",
      "Epoch 14/1000\n",
      "13/13 - 0s - loss: 0.6727 - val_loss: 0.6452\n",
      "Epoch 15/1000\n",
      "13/13 - 0s - loss: 0.6712 - val_loss: 0.6440\n",
      "Epoch 16/1000\n",
      "13/13 - 0s - loss: 0.6688 - val_loss: 0.6388\n",
      "Epoch 17/1000\n",
      "13/13 - 0s - loss: 0.6656 - val_loss: 0.6350\n",
      "Epoch 18/1000\n",
      "13/13 - 0s - loss: 0.6616 - val_loss: 0.6279\n",
      "Epoch 19/1000\n",
      "13/13 - 0s - loss: 0.6555 - val_loss: 0.6217\n",
      "Epoch 20/1000\n",
      "13/13 - 0s - loss: 0.6454 - val_loss: 0.6063\n",
      "Epoch 21/1000\n",
      "13/13 - 0s - loss: 0.6305 - val_loss: 0.5935\n",
      "Epoch 22/1000\n",
      "13/13 - 0s - loss: 0.6073 - val_loss: 0.5638\n",
      "Epoch 23/1000\n",
      "13/13 - 0s - loss: 0.5701 - val_loss: 0.5228\n",
      "Epoch 24/1000\n",
      "13/13 - 0s - loss: 0.5187 - val_loss: 0.4695\n",
      "Epoch 25/1000\n",
      "13/13 - 0s - loss: 0.4519 - val_loss: 0.4063\n",
      "Epoch 26/1000\n",
      "13/13 - 0s - loss: 0.3844 - val_loss: 0.3849\n",
      "Epoch 27/1000\n",
      "13/13 - 0s - loss: 0.3232 - val_loss: 0.3094\n",
      "Epoch 28/1000\n",
      "13/13 - 0s - loss: 0.2911 - val_loss: 0.3170\n",
      "Epoch 29/1000\n",
      "13/13 - 0s - loss: 0.2650 - val_loss: 0.2983\n",
      "Epoch 30/1000\n",
      "13/13 - 0s - loss: 0.2484 - val_loss: 0.2833\n",
      "Epoch 31/1000\n",
      "13/13 - 0s - loss: 0.2431 - val_loss: 0.3055\n",
      "Epoch 32/1000\n",
      "13/13 - 0s - loss: 0.2189 - val_loss: 0.2753\n",
      "Epoch 33/1000\n",
      "13/13 - 0s - loss: 0.2182 - val_loss: 0.2828\n",
      "Epoch 34/1000\n",
      "13/13 - 0s - loss: 0.2086 - val_loss: 0.2664\n",
      "Epoch 35/1000\n",
      "13/13 - 0s - loss: 0.2087 - val_loss: 0.2651\n",
      "Epoch 36/1000\n",
      "13/13 - 0s - loss: 0.2009 - val_loss: 0.2616\n",
      "Epoch 37/1000\n",
      "13/13 - 0s - loss: 0.1978 - val_loss: 0.2651\n",
      "Epoch 38/1000\n",
      "13/13 - 0s - loss: 0.2010 - val_loss: 0.2575\n",
      "Epoch 39/1000\n",
      "13/13 - 0s - loss: 0.1994 - val_loss: 0.2750\n",
      "Epoch 40/1000\n",
      "13/13 - 0s - loss: 0.1945 - val_loss: 0.2523\n",
      "Epoch 41/1000\n",
      "13/13 - 0s - loss: 0.1886 - val_loss: 0.2496\n",
      "Epoch 42/1000\n",
      "13/13 - 0s - loss: 0.1903 - val_loss: 0.2482\n",
      "Epoch 43/1000\n",
      "13/13 - 0s - loss: 0.1851 - val_loss: 0.2490\n",
      "Epoch 44/1000\n",
      "13/13 - 0s - loss: 0.1863 - val_loss: 0.2486\n",
      "Epoch 45/1000\n",
      "13/13 - 0s - loss: 0.1819 - val_loss: 0.2415\n",
      "Epoch 46/1000\n",
      "13/13 - 0s - loss: 0.1876 - val_loss: 0.2395\n",
      "Epoch 47/1000\n",
      "13/13 - 0s - loss: 0.1891 - val_loss: 0.2402\n",
      "Epoch 48/1000\n",
      "13/13 - 0s - loss: 0.1846 - val_loss: 0.2346\n",
      "Epoch 49/1000\n",
      "13/13 - 0s - loss: 0.1805 - val_loss: 0.2327\n",
      "Epoch 50/1000\n",
      "13/13 - 0s - loss: 0.1762 - val_loss: 0.2335\n",
      "Epoch 51/1000\n",
      "13/13 - 0s - loss: 0.1742 - val_loss: 0.2291\n",
      "Epoch 52/1000\n",
      "13/13 - 0s - loss: 0.1732 - val_loss: 0.2283\n",
      "Epoch 53/1000\n",
      "13/13 - 0s - loss: 0.1727 - val_loss: 0.2258\n",
      "Epoch 54/1000\n",
      "13/13 - 0s - loss: 0.1724 - val_loss: 0.2263\n",
      "Epoch 55/1000\n",
      "13/13 - 0s - loss: 0.1703 - val_loss: 0.2272\n",
      "Epoch 56/1000\n",
      "13/13 - 0s - loss: 0.1752 - val_loss: 0.2257\n",
      "Epoch 57/1000\n",
      "13/13 - 0s - loss: 0.1694 - val_loss: 0.2250\n",
      "Epoch 58/1000\n",
      "13/13 - 0s - loss: 0.1702 - val_loss: 0.2228\n",
      "Epoch 59/1000\n",
      "13/13 - 0s - loss: 0.1672 - val_loss: 0.2174\n",
      "Epoch 60/1000\n",
      "13/13 - 0s - loss: 0.1672 - val_loss: 0.2160\n",
      "Epoch 61/1000\n",
      "13/13 - 0s - loss: 0.1657 - val_loss: 0.2159\n",
      "Epoch 62/1000\n",
      "13/13 - 0s - loss: 0.1636 - val_loss: 0.2140\n",
      "Epoch 63/1000\n",
      "13/13 - 0s - loss: 0.1624 - val_loss: 0.2116\n",
      "Epoch 64/1000\n",
      "13/13 - 0s - loss: 0.1646 - val_loss: 0.2100\n",
      "Epoch 65/1000\n",
      "13/13 - 0s - loss: 0.1662 - val_loss: 0.2114\n",
      "Epoch 66/1000\n",
      "13/13 - 0s - loss: 0.1624 - val_loss: 0.2077\n",
      "Epoch 67/1000\n",
      "13/13 - 0s - loss: 0.1623 - val_loss: 0.2067\n",
      "Epoch 68/1000\n",
      "13/13 - 0s - loss: 0.1586 - val_loss: 0.2047\n",
      "Epoch 69/1000\n",
      "13/13 - 0s - loss: 0.1582 - val_loss: 0.2039\n",
      "Epoch 70/1000\n",
      "13/13 - 0s - loss: 0.1578 - val_loss: 0.2024\n",
      "Epoch 71/1000\n",
      "13/13 - 0s - loss: 0.1567 - val_loss: 0.2013\n",
      "Epoch 72/1000\n",
      "13/13 - 0s - loss: 0.1604 - val_loss: 0.2037\n",
      "Epoch 73/1000\n",
      "13/13 - 0s - loss: 0.1587 - val_loss: 0.1994\n",
      "Epoch 74/1000\n",
      "13/13 - 0s - loss: 0.1542 - val_loss: 0.1970\n",
      "Epoch 75/1000\n",
      "13/13 - 0s - loss: 0.1574 - val_loss: 0.2002\n",
      "Epoch 76/1000\n",
      "13/13 - 0s - loss: 0.1543 - val_loss: 0.1952\n",
      "Epoch 77/1000\n",
      "13/13 - 0s - loss: 0.1530 - val_loss: 0.1966\n",
      "Epoch 78/1000\n",
      "13/13 - 0s - loss: 0.1513 - val_loss: 0.1924\n",
      "Epoch 79/1000\n",
      "13/13 - 0s - loss: 0.1527 - val_loss: 0.1916\n",
      "Epoch 80/1000\n",
      "13/13 - 0s - loss: 0.1497 - val_loss: 0.1960\n",
      "Epoch 81/1000\n",
      "13/13 - 0s - loss: 0.1519 - val_loss: 0.1890\n",
      "Epoch 82/1000\n",
      "13/13 - 0s - loss: 0.1490 - val_loss: 0.1908\n",
      "Epoch 83/1000\n",
      "13/13 - 0s - loss: 0.1499 - val_loss: 0.1868\n",
      "Epoch 84/1000\n",
      "13/13 - 0s - loss: 0.1481 - val_loss: 0.1865\n",
      "Epoch 85/1000\n",
      "13/13 - 0s - loss: 0.1473 - val_loss: 0.1852\n",
      "Epoch 86/1000\n",
      "13/13 - 0s - loss: 0.1475 - val_loss: 0.1848\n",
      "Epoch 87/1000\n",
      "13/13 - 0s - loss: 0.1465 - val_loss: 0.1921\n",
      "Epoch 88/1000\n",
      "13/13 - 0s - loss: 0.1485 - val_loss: 0.1825\n",
      "Epoch 89/1000\n",
      "13/13 - 0s - loss: 0.1467 - val_loss: 0.1950\n",
      "Epoch 90/1000\n",
      "13/13 - 0s - loss: 0.1537 - val_loss: 0.1810\n",
      "Epoch 91/1000\n",
      "13/13 - 0s - loss: 0.1471 - val_loss: 0.1858\n",
      "Epoch 92/1000\n",
      "13/13 - 0s - loss: 0.1430 - val_loss: 0.1794\n",
      "Epoch 93/1000\n",
      "13/13 - 0s - loss: 0.1423 - val_loss: 0.1777\n",
      "Epoch 94/1000\n",
      "13/13 - 0s - loss: 0.1422 - val_loss: 0.1797\n",
      "Epoch 95/1000\n",
      "13/13 - 0s - loss: 0.1409 - val_loss: 0.1769\n",
      "Epoch 96/1000\n",
      "13/13 - 0s - loss: 0.1416 - val_loss: 0.1748\n",
      "Epoch 97/1000\n",
      "13/13 - 0s - loss: 0.1402 - val_loss: 0.1767\n",
      "Epoch 98/1000\n",
      "13/13 - 0s - loss: 0.1443 - val_loss: 0.1740\n",
      "Epoch 99/1000\n",
      "13/13 - 0s - loss: 0.1441 - val_loss: 0.1785\n",
      "Epoch 100/1000\n",
      "13/13 - 0s - loss: 0.1384 - val_loss: 0.1702\n",
      "Epoch 101/1000\n",
      "13/13 - 0s - loss: 0.1383 - val_loss: 0.1754\n",
      "Epoch 102/1000\n",
      "13/13 - 0s - loss: 0.1382 - val_loss: 0.1677\n",
      "Epoch 103/1000\n",
      "13/13 - 0s - loss: 0.1421 - val_loss: 0.1679\n",
      "Epoch 104/1000\n",
      "13/13 - 0s - loss: 0.1368 - val_loss: 0.1686\n",
      "Epoch 105/1000\n",
      "13/13 - 0s - loss: 0.1374 - val_loss: 0.1700\n",
      "Epoch 106/1000\n",
      "13/13 - 0s - loss: 0.1370 - val_loss: 0.1636\n",
      "Epoch 107/1000\n",
      "13/13 - 0s - loss: 0.1402 - val_loss: 0.1755\n",
      "Epoch 108/1000\n",
      "13/13 - 0s - loss: 0.1354 - val_loss: 0.1621\n",
      "Epoch 109/1000\n",
      "13/13 - 0s - loss: 0.1363 - val_loss: 0.1606\n",
      "Epoch 110/1000\n",
      "13/13 - 0s - loss: 0.1348 - val_loss: 0.1675\n",
      "Epoch 111/1000\n",
      "13/13 - 0s - loss: 0.1328 - val_loss: 0.1591\n",
      "Epoch 112/1000\n",
      "13/13 - 0s - loss: 0.1310 - val_loss: 0.1652\n",
      "Epoch 113/1000\n",
      "13/13 - 0s - loss: 0.1318 - val_loss: 0.1587\n",
      "Epoch 114/1000\n",
      "13/13 - 0s - loss: 0.1296 - val_loss: 0.1565\n",
      "Epoch 115/1000\n",
      "13/13 - 0s - loss: 0.1305 - val_loss: 0.1563\n",
      "Epoch 116/1000\n",
      "13/13 - 0s - loss: 0.1287 - val_loss: 0.1555\n",
      "Epoch 117/1000\n",
      "13/13 - 0s - loss: 0.1306 - val_loss: 0.1535\n",
      "Epoch 118/1000\n",
      "13/13 - 0s - loss: 0.1270 - val_loss: 0.1557\n",
      "Epoch 119/1000\n",
      "13/13 - 0s - loss: 0.1285 - val_loss: 0.1503\n",
      "Epoch 120/1000\n",
      "13/13 - 0s - loss: 0.1328 - val_loss: 0.1611\n",
      "Epoch 121/1000\n",
      "13/13 - 0s - loss: 0.1275 - val_loss: 0.1498\n",
      "Epoch 122/1000\n",
      "13/13 - 0s - loss: 0.1256 - val_loss: 0.1570\n",
      "Epoch 123/1000\n",
      "13/13 - 0s - loss: 0.1269 - val_loss: 0.1475\n",
      "Epoch 124/1000\n",
      "13/13 - 0s - loss: 0.1266 - val_loss: 0.1475\n",
      "Epoch 125/1000\n",
      "13/13 - 0s - loss: 0.1211 - val_loss: 0.1540\n",
      "Epoch 126/1000\n",
      "13/13 - 0s - loss: 0.1242 - val_loss: 0.1463\n",
      "Epoch 127/1000\n",
      "13/13 - 0s - loss: 0.1212 - val_loss: 0.1434\n",
      "Epoch 128/1000\n",
      "13/13 - 0s - loss: 0.1217 - val_loss: 0.1430\n",
      "Epoch 129/1000\n",
      "13/13 - 0s - loss: 0.1191 - val_loss: 0.1455\n",
      "Epoch 130/1000\n",
      "13/13 - 0s - loss: 0.1220 - val_loss: 0.1503\n",
      "Epoch 131/1000\n",
      "13/13 - 0s - loss: 0.1195 - val_loss: 0.1412\n",
      "Epoch 132/1000\n",
      "13/13 - 0s - loss: 0.1191 - val_loss: 0.1576\n",
      "Epoch 133/1000\n",
      "13/13 - 0s - loss: 0.1276 - val_loss: 0.1432\n",
      "Epoch 134/1000\n",
      "13/13 - 0s - loss: 0.1165 - val_loss: 0.1363\n",
      "Epoch 135/1000\n",
      "13/13 - 0s - loss: 0.1190 - val_loss: 0.1378\n",
      "Epoch 136/1000\n",
      "13/13 - 0s - loss: 0.1159 - val_loss: 0.1345\n",
      "Epoch 137/1000\n",
      "13/13 - 0s - loss: 0.1152 - val_loss: 0.1349\n",
      "Epoch 138/1000\n",
      "13/13 - 0s - loss: 0.1132 - val_loss: 0.1349\n",
      "Epoch 139/1000\n",
      "13/13 - 0s - loss: 0.1126 - val_loss: 0.1324\n",
      "Epoch 140/1000\n",
      "13/13 - 0s - loss: 0.1171 - val_loss: 0.1374\n",
      "Epoch 141/1000\n",
      "13/13 - 0s - loss: 0.1094 - val_loss: 0.1294\n",
      "Epoch 142/1000\n",
      "13/13 - 0s - loss: 0.1153 - val_loss: 0.1422\n",
      "Epoch 143/1000\n",
      "13/13 - 0s - loss: 0.1100 - val_loss: 0.1269\n",
      "Epoch 144/1000\n",
      "13/13 - 0s - loss: 0.1084 - val_loss: 0.1356\n",
      "Epoch 145/1000\n",
      "13/13 - 0s - loss: 0.1133 - val_loss: 0.1251\n",
      "Epoch 146/1000\n",
      "13/13 - 0s - loss: 0.1096 - val_loss: 0.1262\n",
      "Epoch 147/1000\n",
      "13/13 - 0s - loss: 0.1071 - val_loss: 0.1228\n",
      "Epoch 148/1000\n",
      "13/13 - 0s - loss: 0.1075 - val_loss: 0.1249\n",
      "Epoch 149/1000\n",
      "13/13 - 0s - loss: 0.1088 - val_loss: 0.1280\n",
      "Epoch 150/1000\n",
      "13/13 - 0s - loss: 0.1077 - val_loss: 0.1226\n",
      "Epoch 151/1000\n",
      "13/13 - 0s - loss: 0.1072 - val_loss: 0.1205\n",
      "Epoch 152/1000\n",
      "13/13 - 0s - loss: 0.1092 - val_loss: 0.1301\n",
      "Epoch 153/1000\n",
      "13/13 - 0s - loss: 0.1062 - val_loss: 0.1173\n",
      "Epoch 154/1000\n",
      "13/13 - 0s - loss: 0.1071 - val_loss: 0.1161\n",
      "Epoch 155/1000\n",
      "13/13 - 0s - loss: 0.1049 - val_loss: 0.1220\n",
      "Epoch 156/1000\n",
      "13/13 - 0s - loss: 0.1009 - val_loss: 0.1159\n",
      "Epoch 157/1000\n",
      "13/13 - 0s - loss: 0.1027 - val_loss: 0.1318\n",
      "Epoch 158/1000\n",
      "13/13 - 0s - loss: 0.1068 - val_loss: 0.1134\n",
      "Epoch 159/1000\n",
      "13/13 - 0s - loss: 0.1010 - val_loss: 0.1127\n",
      "Epoch 160/1000\n",
      "13/13 - 0s - loss: 0.0977 - val_loss: 0.1126\n",
      "Epoch 161/1000\n",
      "13/13 - 0s - loss: 0.0951 - val_loss: 0.1091\n",
      "Epoch 162/1000\n",
      "13/13 - 0s - loss: 0.0940 - val_loss: 0.1105\n",
      "Epoch 163/1000\n",
      "13/13 - 0s - loss: 0.1016 - val_loss: 0.1062\n",
      "Epoch 164/1000\n",
      "13/13 - 0s - loss: 0.0944 - val_loss: 0.1072\n",
      "Epoch 165/1000\n",
      "13/13 - 0s - loss: 0.0924 - val_loss: 0.1030\n",
      "Epoch 166/1000\n",
      "13/13 - 0s - loss: 0.0911 - val_loss: 0.1064\n",
      "Epoch 167/1000\n",
      "13/13 - 0s - loss: 0.0926 - val_loss: 0.1063\n",
      "Epoch 168/1000\n",
      "13/13 - 0s - loss: 0.0938 - val_loss: 0.1083\n",
      "Epoch 169/1000\n",
      "13/13 - 0s - loss: 0.0902 - val_loss: 0.0984\n",
      "Epoch 170/1000\n",
      "13/13 - 0s - loss: 0.0887 - val_loss: 0.1057\n",
      "Epoch 171/1000\n",
      "13/13 - 0s - loss: 0.0866 - val_loss: 0.0969\n",
      "Epoch 172/1000\n",
      "13/13 - 0s - loss: 0.0862 - val_loss: 0.0958\n",
      "Epoch 173/1000\n",
      "13/13 - 0s - loss: 0.0876 - val_loss: 0.1052\n",
      "Epoch 174/1000\n",
      "13/13 - 0s - loss: 0.0846 - val_loss: 0.0929\n",
      "Epoch 175/1000\n",
      "13/13 - 0s - loss: 0.0862 - val_loss: 0.0933\n",
      "Epoch 176/1000\n",
      "13/13 - 0s - loss: 0.0854 - val_loss: 0.1318\n",
      "Epoch 177/1000\n",
      "13/13 - 0s - loss: 0.0892 - val_loss: 0.0965\n",
      "Epoch 178/1000\n",
      "13/13 - 0s - loss: 0.0852 - val_loss: 0.0939\n",
      "Epoch 179/1000\n",
      "13/13 - 0s - loss: 0.0810 - val_loss: 0.0912\n",
      "Epoch 180/1000\n",
      "13/13 - 0s - loss: 0.0822 - val_loss: 0.0886\n",
      "Epoch 181/1000\n",
      "13/13 - 0s - loss: 0.0780 - val_loss: 0.0970\n",
      "Epoch 182/1000\n",
      "13/13 - 0s - loss: 0.0814 - val_loss: 0.0896\n",
      "Epoch 183/1000\n",
      "13/13 - 0s - loss: 0.0793 - val_loss: 0.0879\n",
      "Epoch 184/1000\n",
      "13/13 - 0s - loss: 0.0783 - val_loss: 0.0947\n",
      "Epoch 185/1000\n",
      "13/13 - 0s - loss: 0.0752 - val_loss: 0.0845\n",
      "Epoch 186/1000\n",
      "13/13 - 0s - loss: 0.0752 - val_loss: 0.0951\n",
      "Epoch 187/1000\n",
      "13/13 - 0s - loss: 0.0763 - val_loss: 0.0837\n",
      "Epoch 188/1000\n",
      "13/13 - 0s - loss: 0.0753 - val_loss: 0.0838\n",
      "Epoch 189/1000\n",
      "13/13 - 0s - loss: 0.0762 - val_loss: 0.0809\n",
      "Epoch 190/1000\n",
      "13/13 - 0s - loss: 0.0761 - val_loss: 0.0797\n",
      "Epoch 191/1000\n",
      "13/13 - 0s - loss: 0.0798 - val_loss: 0.1102\n",
      "Epoch 192/1000\n",
      "13/13 - 0s - loss: 0.0752 - val_loss: 0.0772\n",
      "Epoch 193/1000\n",
      "13/13 - 0s - loss: 0.0713 - val_loss: 0.0761\n",
      "Epoch 194/1000\n",
      "13/13 - 0s - loss: 0.0703 - val_loss: 0.0750\n",
      "Epoch 195/1000\n",
      "13/13 - 0s - loss: 0.0697 - val_loss: 0.0747\n",
      "Epoch 196/1000\n",
      "13/13 - 0s - loss: 0.0788 - val_loss: 0.0742\n",
      "Epoch 197/1000\n",
      "13/13 - 0s - loss: 0.0701 - val_loss: 0.0729\n",
      "Epoch 198/1000\n",
      "13/13 - 0s - loss: 0.0674 - val_loss: 0.0727\n",
      "Epoch 199/1000\n",
      "13/13 - 0s - loss: 0.0677 - val_loss: 0.0806\n",
      "Epoch 200/1000\n",
      "13/13 - 0s - loss: 0.0712 - val_loss: 0.0724\n",
      "Epoch 201/1000\n",
      "13/13 - 0s - loss: 0.0647 - val_loss: 0.0709\n",
      "Epoch 202/1000\n",
      "13/13 - 0s - loss: 0.0662 - val_loss: 0.0706\n",
      "Epoch 203/1000\n",
      "13/13 - 0s - loss: 0.0626 - val_loss: 0.0727\n",
      "Epoch 204/1000\n",
      "13/13 - 0s - loss: 0.0641 - val_loss: 0.0733\n",
      "Epoch 205/1000\n",
      "13/13 - 0s - loss: 0.0680 - val_loss: 0.0680\n",
      "Epoch 206/1000\n",
      "13/13 - 0s - loss: 0.0699 - val_loss: 0.0879\n",
      "Epoch 207/1000\n",
      "13/13 - 0s - loss: 0.0672 - val_loss: 0.0663\n",
      "Epoch 208/1000\n",
      "13/13 - 0s - loss: 0.0592 - val_loss: 0.0657\n",
      "Epoch 209/1000\n",
      "13/13 - 0s - loss: 0.0588 - val_loss: 0.0663\n",
      "Epoch 210/1000\n",
      "13/13 - 0s - loss: 0.0609 - val_loss: 0.0711\n",
      "Epoch 211/1000\n",
      "13/13 - 0s - loss: 0.0576 - val_loss: 0.0684\n",
      "Epoch 212/1000\n",
      "13/13 - 0s - loss: 0.0591 - val_loss: 0.0771\n",
      "Epoch 213/1000\n",
      "13/13 - 0s - loss: 0.0552 - val_loss: 0.0654\n",
      "Epoch 214/1000\n",
      "13/13 - 0s - loss: 0.0615 - val_loss: 0.0631\n",
      "Epoch 215/1000\n",
      "13/13 - 0s - loss: 0.0590 - val_loss: 0.0687\n",
      "Epoch 216/1000\n",
      "13/13 - 0s - loss: 0.0557 - val_loss: 0.0615\n",
      "Epoch 217/1000\n",
      "13/13 - 0s - loss: 0.0557 - val_loss: 0.0619\n",
      "Epoch 218/1000\n",
      "13/13 - 0s - loss: 0.0573 - val_loss: 0.0675\n",
      "Epoch 219/1000\n",
      "13/13 - 0s - loss: 0.0553 - val_loss: 0.0605\n",
      "Epoch 220/1000\n",
      "13/13 - 0s - loss: 0.0515 - val_loss: 0.0601\n",
      "Epoch 221/1000\n",
      "13/13 - 0s - loss: 0.0604 - val_loss: 0.0633\n",
      "Epoch 222/1000\n",
      "13/13 - 0s - loss: 0.0566 - val_loss: 0.0644\n",
      "Epoch 223/1000\n",
      "13/13 - 0s - loss: 0.0647 - val_loss: 0.0726\n",
      "Epoch 224/1000\n",
      "13/13 - 0s - loss: 0.0566 - val_loss: 0.0596\n",
      "Epoch 225/1000\n",
      "13/13 - 0s - loss: 0.0491 - val_loss: 0.0697\n",
      "Epoch 226/1000\n",
      "13/13 - 0s - loss: 0.0497 - val_loss: 0.0576\n",
      "Epoch 227/1000\n",
      "13/13 - 0s - loss: 0.0507 - val_loss: 0.0705\n",
      "Epoch 228/1000\n",
      "13/13 - 0s - loss: 0.0546 - val_loss: 0.0567\n",
      "Epoch 229/1000\n",
      "13/13 - 0s - loss: 0.0509 - val_loss: 0.0568\n",
      "Epoch 230/1000\n",
      "13/13 - 0s - loss: 0.0467 - val_loss: 0.0550\n",
      "Epoch 231/1000\n",
      "13/13 - 0s - loss: 0.0448 - val_loss: 0.0547\n",
      "Epoch 232/1000\n",
      "13/13 - 0s - loss: 0.0444 - val_loss: 0.0529\n",
      "Epoch 233/1000\n",
      "13/13 - 0s - loss: 0.0447 - val_loss: 0.0533\n",
      "Epoch 234/1000\n",
      "13/13 - 0s - loss: 0.0474 - val_loss: 0.0527\n",
      "Epoch 235/1000\n",
      "13/13 - 0s - loss: 0.0499 - val_loss: 0.0718\n",
      "Epoch 236/1000\n",
      "13/13 - 0s - loss: 0.0545 - val_loss: 0.0510\n",
      "Epoch 237/1000\n",
      "13/13 - 0s - loss: 0.0455 - val_loss: 0.0507\n",
      "Epoch 238/1000\n",
      "13/13 - 0s - loss: 0.0454 - val_loss: 0.0491\n",
      "Epoch 239/1000\n",
      "13/13 - 0s - loss: 0.0399 - val_loss: 0.0471\n",
      "Epoch 240/1000\n",
      "13/13 - 0s - loss: 0.0389 - val_loss: 0.0485\n",
      "Epoch 241/1000\n",
      "13/13 - 0s - loss: 0.0401 - val_loss: 0.0518\n",
      "Epoch 242/1000\n",
      "13/13 - 0s - loss: 0.0426 - val_loss: 0.0555\n",
      "Epoch 243/1000\n",
      "13/13 - 0s - loss: 0.0402 - val_loss: 0.0485\n",
      "Epoch 244/1000\n",
      "13/13 - 0s - loss: 0.0390 - val_loss: 0.0476\n",
      "Epoch 00244: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f651bf98e10>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Activation 2\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='sigmoid')) # Hidden 1     \n",
    "model.add(Dense(10, activation='sigmoid')) # Hidden 2\n",
    "model.add(Dense(10)) \n",
    "model.add(Dense(10)) \n",
    "model.add(Dense(1)) #1 Output neuron\n",
    "model.add(Dense(y.shape[1],activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrwXZO30RMLd",
    "outputId": "1c901ebd-d7ee-49f4-c2ab-2d8013243c9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "pred2 = model.predict(x_test)\n",
    "pred2 = np.argmax(pred2, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred2)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kze2miyMReee",
    "outputId": "431dc074-aa8f-418d-91e5-6595fa8c8cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        33\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       104\n",
      "   macro avg       0.98      0.98      0.98       104\n",
      "weighted avg       0.98      0.98      0.98       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nasyjAGxRiac"
   },
   "source": [
    "## Fully Connected Neural Network Model #3 (Using tanh & adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lZcHn4lsRoso",
    "outputId": "3b409fc9-fc6b-4c3d-c3ab-f2b6a38ea4f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 - 1s - loss: 3.4486 - val_loss: 2.7625\n",
      "Epoch 2/1000\n",
      "13/13 - 0s - loss: 3.4361 - val_loss: 2.7601\n",
      "Epoch 3/1000\n",
      "13/13 - 0s - loss: 3.4397 - val_loss: 2.8127\n",
      "Epoch 4/1000\n",
      "13/13 - 0s - loss: 3.4464 - val_loss: 2.7647\n",
      "Epoch 5/1000\n",
      "13/13 - 0s - loss: 3.4341 - val_loss: 2.7675\n",
      "Epoch 6/1000\n",
      "13/13 - 0s - loss: 3.4315 - val_loss: 2.7635\n",
      "Epoch 7/1000\n",
      "13/13 - 0s - loss: 3.4146 - val_loss: 2.7252\n",
      "Epoch 8/1000\n",
      "13/13 - 0s - loss: 3.3974 - val_loss: 2.7053\n",
      "Epoch 9/1000\n",
      "13/13 - 0s - loss: 3.3635 - val_loss: 2.6789\n",
      "Epoch 10/1000\n",
      "13/13 - 0s - loss: 3.3481 - val_loss: 2.6659\n",
      "Epoch 11/1000\n",
      "13/13 - 0s - loss: 3.3405 - val_loss: 2.6619\n",
      "Epoch 12/1000\n",
      "13/13 - 0s - loss: 3.3187 - val_loss: 2.6445\n",
      "Epoch 13/1000\n",
      "13/13 - 0s - loss: 3.3346 - val_loss: 2.6862\n",
      "Epoch 14/1000\n",
      "13/13 - 0s - loss: 3.2757 - val_loss: 1.9465\n",
      "Epoch 15/1000\n",
      "13/13 - 0s - loss: 3.0123 - val_loss: 2.6771\n",
      "Epoch 16/1000\n",
      "13/13 - 0s - loss: 2.0274 - val_loss: 2.0209\n",
      "Epoch 17/1000\n",
      "13/13 - 0s - loss: 2.9057 - val_loss: 3.8512\n",
      "Epoch 18/1000\n",
      "13/13 - 0s - loss: 3.5091 - val_loss: 3.4626\n",
      "Epoch 19/1000\n",
      "13/13 - 0s - loss: 2.2798 - val_loss: 1.4751\n",
      "Epoch 20/1000\n",
      "13/13 - 0s - loss: 1.7755 - val_loss: 1.7697\n",
      "Epoch 21/1000\n",
      "13/13 - 0s - loss: 2.7733 - val_loss: 1.8680\n",
      "Epoch 22/1000\n",
      "13/13 - 0s - loss: 2.1388 - val_loss: 1.3707\n",
      "Epoch 23/1000\n",
      "13/13 - 0s - loss: 1.4423 - val_loss: 1.4141\n",
      "Epoch 24/1000\n",
      "13/13 - 0s - loss: 1.4315 - val_loss: 1.4721\n",
      "Epoch 25/1000\n",
      "13/13 - 0s - loss: 1.4867 - val_loss: 1.3162\n",
      "Epoch 26/1000\n",
      "13/13 - 0s - loss: 1.3735 - val_loss: 1.3110\n",
      "Epoch 27/1000\n",
      "13/13 - 0s - loss: 1.3628 - val_loss: 1.3066\n",
      "Epoch 28/1000\n",
      "13/13 - 0s - loss: 1.3554 - val_loss: 1.3041\n",
      "Epoch 29/1000\n",
      "13/13 - 0s - loss: 1.3493 - val_loss: 1.3032\n",
      "Epoch 30/1000\n",
      "13/13 - 0s - loss: 1.3684 - val_loss: 1.0610\n",
      "Epoch 31/1000\n",
      "13/13 - 0s - loss: 1.4092 - val_loss: 1.2564\n",
      "Epoch 32/1000\n",
      "13/13 - 0s - loss: 1.3302 - val_loss: 1.1554\n",
      "Epoch 33/1000\n",
      "13/13 - 0s - loss: 1.7526 - val_loss: 3.3155\n",
      "Epoch 34/1000\n",
      "13/13 - 0s - loss: 4.2111 - val_loss: 5.0228\n",
      "Epoch 35/1000\n",
      "13/13 - 0s - loss: 4.9018 - val_loss: 4.8053\n",
      "Epoch 00035: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6511e70090>"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Activation3\n",
    "model.add(Dense(10, input_dim=x.shape[1], activation='tanh')) # Hidden 1     \n",
    "model.add(Dense(30, activation='tanh')) # Hidden 2\n",
    "model.add(Dense(10)) \n",
    "model.add(Dense(10)) \n",
    "model.add(Dense(1)) #1 Output neuron\n",
    "model.add(Dense(y.shape[1],activation='tanh'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPM51ZodR2hj",
    "outputId": "77f6b2a3-eb13-4ca8-ec01-3fa4b7e5c04b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5096153846153846\n"
     ]
    }
   ],
   "source": [
    "pred3 = model.predict(x_test)\n",
    "pred3 = np.argmax(pred3, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred3)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWMTxLnpR6cA",
    "outputId": "46be0eda-49f3-4d28-db10-e2c829d1aa5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      1.00      0.56        33\n",
      "           1       1.00      0.28      0.44        71\n",
      "\n",
      "    accuracy                           0.51       104\n",
      "   macro avg       0.70      0.64      0.50       104\n",
      "weighted avg       0.81      0.51      0.48       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kh5JHUvpSvJ6"
   },
   "source": [
    "## Fully Connected Neural Network Model #4 (Using relu & sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gDLnx-dISzwY",
    "outputId": "067f6de2-9453-417f-f7ab-90cd4dab13c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 - 1s - loss: 7.7125 - val_loss: 7.7125\n",
      "Epoch 2/1000\n",
      "13/13 - 0s - loss: 7.7125 - val_loss: 7.7125\n",
      "Epoch 3/1000\n",
      "13/13 - 0s - loss: 7.7125 - val_loss: 7.7125\n",
      "Epoch 4/1000\n",
      "13/13 - 0s - loss: 7.7125 - val_loss: 7.7125\n",
      "Epoch 5/1000\n",
      "13/13 - 0s - loss: 7.7125 - val_loss: 7.7125\n",
      "Epoch 6/1000\n",
      "13/13 - 0s - loss: 7.7125 - val_loss: 7.7125\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f652488af50>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Activation 4\n",
    "model.add(Dense(30, input_dim=x.shape[1], activation='relu')) # Hidden 1     \n",
    "model.add(Dense(15, activation='relu')) # Hidden 2\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(10,activation='relu'))\n",
    "model.add(Dense(1)) #1 Output neuron\n",
    "model.add(Dense(y.shape[1],activation='relu'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mv8YOl_WTDSA",
    "outputId": "cf344c03-21f9-47fa-9c40-4df2b69f96cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.3173076923076923\n"
     ]
    }
   ],
   "source": [
    "pred4 = model.predict(x_test)\n",
    "pred4 = np.argmax(pred4, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred4)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvcwHCvTTHuF",
    "outputId": "421d04c8-5c0f-4eb3-c55f-69a542ef1c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.48        33\n",
      "           1       0.00      0.00      0.00        71\n",
      "\n",
      "    accuracy                           0.32       104\n",
      "   macro avg       0.16      0.50      0.24       104\n",
      "weighted avg       0.10      0.32      0.15       104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwsB_uyEULxT"
   },
   "source": [
    "## Fully Connected Neural Network Model #5 (Using sigmoid & sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TSroPuUbURKs",
    "outputId": "935b2874-1875-4b6a-8317-9aa151dd2b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 - 1s - loss: 0.7215 - val_loss: 0.6888\n",
      "Epoch 2/1000\n",
      "13/13 - 0s - loss: 0.7031 - val_loss: 0.6813\n",
      "Epoch 3/1000\n",
      "13/13 - 0s - loss: 0.6949 - val_loss: 0.6785\n",
      "Epoch 4/1000\n",
      "13/13 - 0s - loss: 0.6910 - val_loss: 0.6774\n",
      "Epoch 5/1000\n",
      "13/13 - 0s - loss: 0.6889 - val_loss: 0.6768\n",
      "Epoch 6/1000\n",
      "13/13 - 0s - loss: 0.6878 - val_loss: 0.6763\n",
      "Epoch 7/1000\n",
      "13/13 - 0s - loss: 0.6869 - val_loss: 0.6758\n",
      "Epoch 8/1000\n",
      "13/13 - 0s - loss: 0.6863 - val_loss: 0.6753\n",
      "Epoch 9/1000\n",
      "13/13 - 0s - loss: 0.6858 - val_loss: 0.6747\n",
      "Epoch 10/1000\n",
      "13/13 - 0s - loss: 0.6855 - val_loss: 0.6742\n",
      "Epoch 11/1000\n",
      "13/13 - 0s - loss: 0.6850 - val_loss: 0.6733\n",
      "Epoch 12/1000\n",
      "13/13 - 0s - loss: 0.6846 - val_loss: 0.6727\n",
      "Epoch 13/1000\n",
      "13/13 - 0s - loss: 0.6842 - val_loss: 0.6720\n",
      "Epoch 14/1000\n",
      "13/13 - 0s - loss: 0.6839 - val_loss: 0.6713\n",
      "Epoch 15/1000\n",
      "13/13 - 0s - loss: 0.6835 - val_loss: 0.6706\n",
      "Epoch 16/1000\n",
      "13/13 - 0s - loss: 0.6831 - val_loss: 0.6699\n",
      "Epoch 17/1000\n",
      "13/13 - 0s - loss: 0.6828 - val_loss: 0.6693\n",
      "Epoch 18/1000\n",
      "13/13 - 0s - loss: 0.6825 - val_loss: 0.6686\n",
      "Epoch 19/1000\n",
      "13/13 - 0s - loss: 0.6822 - val_loss: 0.6680\n",
      "Epoch 20/1000\n",
      "13/13 - 0s - loss: 0.6820 - val_loss: 0.6674\n",
      "Epoch 21/1000\n",
      "13/13 - 0s - loss: 0.6817 - val_loss: 0.6668\n",
      "Epoch 22/1000\n",
      "13/13 - 0s - loss: 0.6813 - val_loss: 0.6662\n",
      "Epoch 23/1000\n",
      "13/13 - 0s - loss: 0.6811 - val_loss: 0.6656\n",
      "Epoch 24/1000\n",
      "13/13 - 0s - loss: 0.6808 - val_loss: 0.6650\n",
      "Epoch 25/1000\n",
      "13/13 - 0s - loss: 0.6806 - val_loss: 0.6645\n",
      "Epoch 26/1000\n",
      "13/13 - 0s - loss: 0.6804 - val_loss: 0.6639\n",
      "Epoch 27/1000\n",
      "13/13 - 0s - loss: 0.6801 - val_loss: 0.6634\n",
      "Epoch 28/1000\n",
      "13/13 - 0s - loss: 0.6799 - val_loss: 0.6630\n",
      "Epoch 29/1000\n",
      "13/13 - 0s - loss: 0.6798 - val_loss: 0.6624\n",
      "Epoch 30/1000\n",
      "13/13 - 0s - loss: 0.6795 - val_loss: 0.6620\n",
      "Epoch 31/1000\n",
      "13/13 - 0s - loss: 0.6793 - val_loss: 0.6616\n",
      "Epoch 32/1000\n",
      "13/13 - 0s - loss: 0.6791 - val_loss: 0.6611\n",
      "Epoch 33/1000\n",
      "13/13 - 0s - loss: 0.6789 - val_loss: 0.6606\n",
      "Epoch 34/1000\n",
      "13/13 - 0s - loss: 0.6787 - val_loss: 0.6601\n",
      "Epoch 35/1000\n",
      "13/13 - 0s - loss: 0.6786 - val_loss: 0.6596\n",
      "Epoch 36/1000\n",
      "13/13 - 0s - loss: 0.6784 - val_loss: 0.6592\n",
      "Epoch 37/1000\n",
      "13/13 - 0s - loss: 0.6782 - val_loss: 0.6588\n",
      "Epoch 38/1000\n",
      "13/13 - 0s - loss: 0.6781 - val_loss: 0.6582\n",
      "Epoch 39/1000\n",
      "13/13 - 0s - loss: 0.6779 - val_loss: 0.6579\n",
      "Epoch 40/1000\n",
      "13/13 - 0s - loss: 0.6778 - val_loss: 0.6574\n",
      "Epoch 41/1000\n",
      "13/13 - 0s - loss: 0.6776 - val_loss: 0.6571\n",
      "Epoch 42/1000\n",
      "13/13 - 0s - loss: 0.6775 - val_loss: 0.6568\n",
      "Epoch 43/1000\n",
      "13/13 - 0s - loss: 0.6774 - val_loss: 0.6565\n",
      "Epoch 44/1000\n",
      "13/13 - 0s - loss: 0.6773 - val_loss: 0.6560\n",
      "Epoch 45/1000\n",
      "13/13 - 0s - loss: 0.6771 - val_loss: 0.6557\n",
      "Epoch 46/1000\n",
      "13/13 - 0s - loss: 0.6770 - val_loss: 0.6553\n",
      "Epoch 47/1000\n",
      "13/13 - 0s - loss: 0.6770 - val_loss: 0.6549\n",
      "Epoch 48/1000\n",
      "13/13 - 0s - loss: 0.6768 - val_loss: 0.6546\n",
      "Epoch 49/1000\n",
      "13/13 - 0s - loss: 0.6766 - val_loss: 0.6542\n",
      "Epoch 50/1000\n",
      "13/13 - 0s - loss: 0.6766 - val_loss: 0.6540\n",
      "Epoch 51/1000\n",
      "13/13 - 0s - loss: 0.6764 - val_loss: 0.6536\n",
      "Epoch 52/1000\n",
      "13/13 - 0s - loss: 0.6763 - val_loss: 0.6534\n",
      "Epoch 53/1000\n",
      "13/13 - 0s - loss: 0.6762 - val_loss: 0.6531\n",
      "Epoch 54/1000\n",
      "13/13 - 0s - loss: 0.6761 - val_loss: 0.6529\n",
      "Epoch 55/1000\n",
      "13/13 - 0s - loss: 0.6760 - val_loss: 0.6526\n",
      "Epoch 56/1000\n",
      "13/13 - 0s - loss: 0.6760 - val_loss: 0.6524\n",
      "Epoch 57/1000\n",
      "13/13 - 0s - loss: 0.6759 - val_loss: 0.6522\n",
      "Epoch 58/1000\n",
      "13/13 - 0s - loss: 0.6758 - val_loss: 0.6521\n",
      "Epoch 59/1000\n",
      "13/13 - 0s - loss: 0.6758 - val_loss: 0.6519\n",
      "Epoch 60/1000\n",
      "13/13 - 0s - loss: 0.6757 - val_loss: 0.6516\n",
      "Epoch 61/1000\n",
      "13/13 - 0s - loss: 0.6756 - val_loss: 0.6512\n",
      "Epoch 62/1000\n",
      "13/13 - 0s - loss: 0.6756 - val_loss: 0.6510\n",
      "Epoch 63/1000\n",
      "13/13 - 0s - loss: 0.6755 - val_loss: 0.6508\n",
      "Epoch 64/1000\n",
      "13/13 - 0s - loss: 0.6754 - val_loss: 0.6506\n",
      "Epoch 65/1000\n",
      "13/13 - 0s - loss: 0.6753 - val_loss: 0.6504\n",
      "Epoch 66/1000\n",
      "13/13 - 0s - loss: 0.6752 - val_loss: 0.6501\n",
      "Epoch 67/1000\n",
      "13/13 - 0s - loss: 0.6752 - val_loss: 0.6498\n",
      "Epoch 68/1000\n",
      "13/13 - 0s - loss: 0.6751 - val_loss: 0.6496\n",
      "Epoch 69/1000\n",
      "13/13 - 0s - loss: 0.6751 - val_loss: 0.6494\n",
      "Epoch 70/1000\n",
      "13/13 - 0s - loss: 0.6751 - val_loss: 0.6491\n",
      "Epoch 71/1000\n",
      "13/13 - 0s - loss: 0.6750 - val_loss: 0.6489\n",
      "Epoch 72/1000\n",
      "13/13 - 0s - loss: 0.6749 - val_loss: 0.6488\n",
      "Epoch 73/1000\n",
      "13/13 - 0s - loss: 0.6748 - val_loss: 0.6486\n",
      "Epoch 74/1000\n",
      "13/13 - 0s - loss: 0.6748 - val_loss: 0.6484\n",
      "Epoch 75/1000\n",
      "13/13 - 0s - loss: 0.6748 - val_loss: 0.6483\n",
      "Epoch 76/1000\n",
      "13/13 - 0s - loss: 0.6748 - val_loss: 0.6482\n",
      "Epoch 77/1000\n",
      "13/13 - 0s - loss: 0.6748 - val_loss: 0.6480\n",
      "Epoch 78/1000\n",
      "13/13 - 0s - loss: 0.6747 - val_loss: 0.6477\n",
      "Epoch 79/1000\n",
      "13/13 - 0s - loss: 0.6746 - val_loss: 0.6476\n",
      "Epoch 80/1000\n",
      "13/13 - 0s - loss: 0.6745 - val_loss: 0.6474\n",
      "Epoch 81/1000\n",
      "13/13 - 0s - loss: 0.6745 - val_loss: 0.6473\n",
      "Epoch 82/1000\n",
      "13/13 - 0s - loss: 0.6745 - val_loss: 0.6470\n",
      "Epoch 83/1000\n",
      "13/13 - 0s - loss: 0.6745 - val_loss: 0.6469\n",
      "Epoch 84/1000\n",
      "13/13 - 0s - loss: 0.6745 - val_loss: 0.6468\n",
      "Epoch 85/1000\n",
      "13/13 - 0s - loss: 0.6745 - val_loss: 0.6468\n",
      "Epoch 86/1000\n",
      "13/13 - 0s - loss: 0.6743 - val_loss: 0.6465\n",
      "Epoch 87/1000\n",
      "13/13 - 0s - loss: 0.6743 - val_loss: 0.6465\n",
      "Epoch 88/1000\n",
      "13/13 - 0s - loss: 0.6743 - val_loss: 0.6464\n",
      "Epoch 89/1000\n",
      "13/13 - 0s - loss: 0.6743 - val_loss: 0.6463\n",
      "Epoch 90/1000\n",
      "13/13 - 0s - loss: 0.6742 - val_loss: 0.6462\n",
      "Epoch 91/1000\n",
      "13/13 - 0s - loss: 0.6742 - val_loss: 0.6461\n",
      "Epoch 92/1000\n",
      "13/13 - 0s - loss: 0.6742 - val_loss: 0.6459\n",
      "Epoch 93/1000\n",
      "13/13 - 0s - loss: 0.6742 - val_loss: 0.6458\n",
      "Epoch 94/1000\n",
      "13/13 - 0s - loss: 0.6741 - val_loss: 0.6456\n",
      "Epoch 95/1000\n",
      "13/13 - 0s - loss: 0.6741 - val_loss: 0.6454\n",
      "Epoch 96/1000\n",
      "13/13 - 0s - loss: 0.6741 - val_loss: 0.6453\n",
      "Epoch 97/1000\n",
      "13/13 - 0s - loss: 0.6741 - val_loss: 0.6452\n",
      "Epoch 98/1000\n",
      "13/13 - 0s - loss: 0.6741 - val_loss: 0.6452\n",
      "Epoch 99/1000\n",
      "13/13 - 0s - loss: 0.6741 - val_loss: 0.6451\n",
      "Epoch 100/1000\n",
      "13/13 - 0s - loss: 0.6739 - val_loss: 0.6449\n",
      "Epoch 101/1000\n",
      "13/13 - 0s - loss: 0.6740 - val_loss: 0.6448\n",
      "Epoch 102/1000\n",
      "13/13 - 0s - loss: 0.6740 - val_loss: 0.6448\n",
      "Epoch 103/1000\n",
      "13/13 - 0s - loss: 0.6739 - val_loss: 0.6448\n",
      "Epoch 104/1000\n",
      "13/13 - 0s - loss: 0.6740 - val_loss: 0.6447\n",
      "Epoch 105/1000\n",
      "13/13 - 0s - loss: 0.6739 - val_loss: 0.6446\n",
      "Epoch 106/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6445\n",
      "Epoch 107/1000\n",
      "13/13 - 0s - loss: 0.6739 - val_loss: 0.6445\n",
      "Epoch 108/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6445\n",
      "Epoch 109/1000\n",
      "13/13 - 0s - loss: 0.6739 - val_loss: 0.6443\n",
      "Epoch 110/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6442\n",
      "Epoch 111/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6439\n",
      "Epoch 112/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6439\n",
      "Epoch 113/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6438\n",
      "Epoch 114/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6437\n",
      "Epoch 115/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6437\n",
      "Epoch 116/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6436\n",
      "Epoch 117/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6436\n",
      "Epoch 118/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6435\n",
      "Epoch 119/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6435\n",
      "Epoch 120/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6433\n",
      "Epoch 121/1000\n",
      "13/13 - 0s - loss: 0.6738 - val_loss: 0.6433\n",
      "Epoch 122/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6433\n",
      "Epoch 123/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6433\n",
      "Epoch 124/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6432\n",
      "Epoch 125/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6430\n",
      "Epoch 126/1000\n",
      "13/13 - 0s - loss: 0.6737 - val_loss: 0.6429\n",
      "Epoch 127/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6430\n",
      "Epoch 128/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6428\n",
      "Epoch 129/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6428\n",
      "Epoch 130/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6426\n",
      "Epoch 131/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6425\n",
      "Epoch 132/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6424\n",
      "Epoch 133/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6424\n",
      "Epoch 134/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6423\n",
      "Epoch 135/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6425\n",
      "Epoch 136/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6424\n",
      "Epoch 137/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6424\n",
      "Epoch 138/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6423\n",
      "Epoch 139/1000\n",
      "13/13 - 0s - loss: 0.6736 - val_loss: 0.6422\n",
      "Epoch 140/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6422\n",
      "Epoch 141/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6421\n",
      "Epoch 142/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6421\n",
      "Epoch 143/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6420\n",
      "Epoch 144/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6421\n",
      "Epoch 145/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6419\n",
      "Epoch 146/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6417\n",
      "Epoch 147/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6418\n",
      "Epoch 148/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6418\n",
      "Epoch 149/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6419\n",
      "Epoch 150/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6417\n",
      "Epoch 151/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6417\n",
      "Epoch 152/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6417\n",
      "Epoch 153/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6417\n",
      "Epoch 154/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6416\n",
      "Epoch 155/1000\n",
      "13/13 - 0s - loss: 0.6735 - val_loss: 0.6416\n",
      "Epoch 156/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6416\n",
      "Epoch 157/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6413\n",
      "Epoch 158/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6413\n",
      "Epoch 159/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6413\n",
      "Epoch 160/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6413\n",
      "Epoch 161/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6412\n",
      "Epoch 162/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6411\n",
      "Epoch 163/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6411\n",
      "Epoch 164/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6411\n",
      "Epoch 165/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6411\n",
      "Epoch 166/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6411\n",
      "Epoch 167/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6412\n",
      "Epoch 168/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6411\n",
      "Epoch 169/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6410\n",
      "Epoch 170/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6411\n",
      "Epoch 171/1000\n",
      "13/13 - 0s - loss: 0.6734 - val_loss: 0.6411\n",
      "Epoch 172/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6410\n",
      "Epoch 173/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6409\n",
      "Epoch 174/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6408\n",
      "Epoch 175/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6407\n",
      "Epoch 176/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6407\n",
      "Epoch 177/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6406\n",
      "Epoch 178/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6406\n",
      "Epoch 179/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6407\n",
      "Epoch 180/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6407\n",
      "Epoch 181/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6406\n",
      "Epoch 182/1000\n",
      "13/13 - 0s - loss: 0.6732 - val_loss: 0.6406\n",
      "Epoch 183/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6406\n",
      "Epoch 184/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6405\n",
      "Epoch 185/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6404\n",
      "Epoch 186/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6405\n",
      "Epoch 187/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6406\n",
      "Epoch 188/1000\n",
      "13/13 - 0s - loss: 0.6733 - val_loss: 0.6405\n",
      "Epoch 189/1000\n",
      "13/13 - 0s - loss: 0.6732 - val_loss: 0.6406\n",
      "Epoch 190/1000\n",
      "13/13 - 0s - loss: 0.6732 - val_loss: 0.6405\n",
      "Epoch 00190: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6511e7a950>"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Activation 5\n",
    "model.add(Dense(30, input_dim=x.shape[1], activation='sigmoid')) # Hidden 1     \n",
    "model.add(Dense(15, activation='sigmoid')) # Hidden 2\n",
    "model.add(Dense(20)) \n",
    "model.add(Dense(30)) \n",
    "model.add(Dense(1)) #1 Output neuron\n",
    "model.add(Dense(y.shape[1],activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbCeIW8DUj5e",
    "outputId": "c9f65b47-97e5-4f50-ad96-7d639cd438da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6826923076923077\n"
     ]
    }
   ],
   "source": [
    "pred5 = model.predict(x_test)\n",
    "pred5 = np.argmax(pred5, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred5)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sg6s5ZcyU1ps",
    "outputId": "85e6330f-d391-4aa3-eed4-794fd10b1696"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.68      1.00      0.81        71\n",
      "\n",
      "    accuracy                           0.68       104\n",
      "   macro avg       0.34      0.50      0.41       104\n",
      "weighted avg       0.47      0.68      0.55       104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVh64_YRU8Vy"
   },
   "source": [
    "## Fully Connected Neural Network Model #6 (Using tanh & sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYWPAZ9KU5qH",
    "outputId": "71de5dd0-acd0-427f-e24a-4ffa25629be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 - 1s - loss: 4.9550 - val_loss: 5.5772\n",
      "Epoch 2/1000\n",
      "13/13 - 0s - loss: 4.9472 - val_loss: 5.5719\n",
      "Epoch 3/1000\n",
      "13/13 - 0s - loss: 4.9381 - val_loss: 5.5937\n",
      "Epoch 4/1000\n",
      "13/13 - 0s - loss: 4.9480 - val_loss: 5.5969\n",
      "Epoch 5/1000\n",
      "13/13 - 0s - loss: 4.9395 - val_loss: 5.5734\n",
      "Epoch 6/1000\n",
      "13/13 - 0s - loss: 4.9370 - val_loss: 5.5627\n",
      "Epoch 7/1000\n",
      "13/13 - 0s - loss: 4.9424 - val_loss: 5.5697\n",
      "Epoch 8/1000\n",
      "13/13 - 0s - loss: 4.9397 - val_loss: 5.5492\n",
      "Epoch 9/1000\n",
      "13/13 - 0s - loss: 4.9378 - val_loss: 5.5777\n",
      "Epoch 10/1000\n",
      "13/13 - 0s - loss: 4.9417 - val_loss: 5.5432\n",
      "Epoch 11/1000\n",
      "13/13 - 0s - loss: 4.9553 - val_loss: 5.5679\n",
      "Epoch 12/1000\n",
      "13/13 - 0s - loss: 4.9251 - val_loss: 5.6101\n",
      "Epoch 13/1000\n",
      "13/13 - 0s - loss: 4.9392 - val_loss: 5.5453\n",
      "Epoch 14/1000\n",
      "13/13 - 0s - loss: 4.9084 - val_loss: 5.5280\n",
      "Epoch 15/1000\n",
      "13/13 - 0s - loss: 4.1892 - val_loss: 2.7394\n",
      "Epoch 16/1000\n",
      "13/13 - 0s - loss: 3.4150 - val_loss: 2.7472\n",
      "Epoch 17/1000\n",
      "13/13 - 0s - loss: 3.4190 - val_loss: 2.7406\n",
      "Epoch 18/1000\n",
      "13/13 - 0s - loss: 3.4194 - val_loss: 2.7441\n",
      "Epoch 19/1000\n",
      "13/13 - 0s - loss: 3.4080 - val_loss: 2.7333\n",
      "Epoch 20/1000\n",
      "13/13 - 0s - loss: 3.4011 - val_loss: 2.7627\n",
      "Epoch 21/1000\n",
      "13/13 - 0s - loss: 3.4044 - val_loss: 2.7775\n",
      "Epoch 22/1000\n",
      "13/13 - 0s - loss: 3.4149 - val_loss: 2.7219\n",
      "Epoch 23/1000\n",
      "13/13 - 0s - loss: 3.4218 - val_loss: 2.7158\n",
      "Epoch 24/1000\n",
      "13/13 - 0s - loss: 3.4113 - val_loss: 2.7407\n",
      "Epoch 25/1000\n",
      "13/13 - 0s - loss: 3.4586 - val_loss: 2.7949\n",
      "Epoch 26/1000\n",
      "13/13 - 0s - loss: 3.4384 - val_loss: 2.7279\n",
      "Epoch 27/1000\n",
      "13/13 - 0s - loss: 3.4097 - val_loss: 2.7547\n",
      "Epoch 28/1000\n",
      "13/13 - 0s - loss: 3.4058 - val_loss: 2.7319\n",
      "Epoch 00028: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f651c27f510>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#Activation 6\n",
    "model.add(Dense(45, input_dim=x.shape[1], activation='tanh')) # Hidden 1     \n",
    "model.add(Dense(30, activation='tanh')) # Hidden 2\n",
    "model.add(Dense(1)) #1 Output neuron\n",
    "model.add(Dense(y.shape[1],activation='tanh'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-5, patience=5, verbose=2, mode='auto')  \n",
    "\n",
    "model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=2,epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yR2XZDneVI2L",
    "outputId": "9a869d34-58b9-489c-d9c7-200eb56616b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.6826923076923077\n"
     ]
    }
   ],
   "source": [
    "pred6 = model.predict(x_test)\n",
    "pred6 = np.argmax(pred6, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred6)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mzDMWEFVMuV",
    "outputId": "3c5c8120-a3d1-4946-a12f-11699eac1c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        33\n",
      "           1       0.68      1.00      0.81        71\n",
      "\n",
      "    accuracy                           0.68       104\n",
      "   macro avg       0.34      0.50      0.41       104\n",
      "weighted avg       0.47      0.68      0.55       104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvqP-IPqnHly"
   },
   "source": [
    "\n",
    "## CNN Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ve5KOXL_gup"
   },
   "source": [
    "Here we set up our data for use with our CNN models. We once again split and trained for CNN model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHa46ZtjJLpw",
    "outputId": "9262a13d-f2b3-4472-ae90-52aa14242899"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((520, 16), (520,))"
      ]
     },
     "execution_count": 52,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x = df.drop('class', 1)\n",
    "x = new_x.values\n",
    "y = df['class'].values\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PsF-KF4UJSOl",
    "outputId": "beec64bd-bef1-4466-b815-dcafbb1c3518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((416, 16), (104, 16), (416,), (104,))"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 42)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZp1NK4BJVZy"
   },
   "source": [
    "## Defining the CNN Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fmZPmSmwnSw1"
   },
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZR4Kn5qEB-YZ"
   },
   "outputs": [],
   "source": [
    "img_rows, img_cols = 1, x_train.shape[1]\n",
    "img_rows_test, img_cols_test = 1, x_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qy92T895Dwk3"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows_test, img_cols_test, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcmAG0u3DzG6",
    "outputId": "db7f879b-8127-4a6b-9c17-2d9b9973c1a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 1, 16, 1)\n",
      "(104, 1, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-jh5rnxD39q",
    "outputId": "781e9cf4-7a59-427a-a7f5-c5fa489222ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSv7Z3KxD6Ip",
    "outputId": "4110025f-a9f3-43ad-e240-1e58182979a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (416, 1, 16, 1)\n",
      "x_test shape: (104, 1, 16, 1)\n",
      "Training samples: 416\n",
      "Test samples: 104\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(\"Training samples: {}\".format(x_train.shape[0]))\n",
    "print(\"Test samples: {}\".format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MiK-KTSMD8LH",
    "outputId": "da3e2709-32fb-4230-8ded-ea9d8a562213"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416,)\n",
      "[1 1 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "royuEOJJD9T5"
   },
   "outputs": [],
   "source": [
    "num_classes = 2 \n",
    "\n",
    "# Converts a class vector (integers) to binary class matrix.   One-hot encoding!  Use with categorical_crossentropy.\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "8Qv14C9UJpnP",
    "outputId": "2095d78b-cb0f-4c38-b2e9-afaadff86c20"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0    0.0  1.0\n",
       "1    0.0  1.0\n",
       "2    1.0  0.0\n",
       "3    1.0  0.0\n",
       "4    1.0  0.0\n",
       "..   ...  ...\n",
       "411  0.0  1.0\n",
       "412  0.0  1.0\n",
       "413  0.0  1.0\n",
       "414  0.0  1.0\n",
       "415  0.0  1.0\n",
       "\n",
       "[416 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "LvZ1dU8iJrUZ",
    "outputId": "dcefa956-37a1-45fd-f065-c19d00da88bd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0    1.0  0.0\n",
       "1    0.0  1.0\n",
       "2    0.0  1.0\n",
       "3    0.0  1.0\n",
       "4    0.0  1.0\n",
       "..   ...  ...\n",
       "99   0.0  1.0\n",
       "100  1.0  0.0\n",
       "101  0.0  1.0\n",
       "102  1.0  0.0\n",
       "103  1.0  0.0\n",
       "\n",
       "[104 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqXvukvKJtwi",
    "outputId": "3298fc57-5977-4938-e811-c7a3e508f5f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((416, 2), (104, 2))"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Crc_p3XETz_"
   },
   "source": [
    "## CNN Model #1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvXrkdmkEMpC"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(1, 2), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 1)))\n",
    "model.add(Conv2D(64, (1, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 3)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eug2Y0T5ERsL",
    "outputId": "aa8f1651-a534-4f90-f627-e9472c72a441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1, 15, 32)         96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 13, 64)         4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1000)              257000    \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 263,258\n",
      "Trainable params: 263,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tblvZ8REgYY"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ifXd3evMEiWP",
    "outputId": "5f3fc5ae-e954-4571-a282-47565f1d2dbf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 1, 16, 1)"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwtBDYXlEkdk",
    "outputId": "8119b31a-2649-499e-956a-116f4ef7eafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 - 1s - loss: 0.7473 - accuracy: 0.6034 - val_loss: 0.5159 - val_accuracy: 0.7692\n",
      "Epoch 2/10\n",
      "13/13 - 0s - loss: 0.5553 - accuracy: 0.7163 - val_loss: 0.4265 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "13/13 - 0s - loss: 0.4137 - accuracy: 0.8534 - val_loss: 0.4688 - val_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "13/13 - 0s - loss: 0.3632 - accuracy: 0.8678 - val_loss: 0.3475 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "13/13 - 0s - loss: 0.3011 - accuracy: 0.8942 - val_loss: 0.3328 - val_accuracy: 0.8558\n",
      "Epoch 6/10\n",
      "13/13 - 0s - loss: 0.2829 - accuracy: 0.8918 - val_loss: 0.3331 - val_accuracy: 0.8558\n",
      "Epoch 7/10\n",
      "13/13 - 0s - loss: 0.2649 - accuracy: 0.8966 - val_loss: 0.3515 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "13/13 - 0s - loss: 0.2617 - accuracy: 0.9014 - val_loss: 0.3563 - val_accuracy: 0.8654\n",
      "Epoch 9/10\n",
      "13/13 - 0s - loss: 0.2512 - accuracy: 0.8990 - val_loss: 0.3377 - val_accuracy: 0.8750\n",
      "Epoch 00009: early stopping\n",
      "Elapsed time: 0:00:01.92\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=4, verbose=2, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test), callbacks=[monitor])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Elapsed time: {}\".format(hms_string(elapsed_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tm30hr79J3cw",
    "outputId": "ae833528-a43e-4719-e6c9-1e6025579af7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33769702911376953, 0.875]"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "cnn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIW74Yv3J8nB",
    "outputId": "0298ce7a-ea80-40eb-8d0f-463e99780b08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.33769702911376953\n",
      "Test accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {}'.format(cnn_score[0]))\n",
    "print('Test accuracy: {}'.format(cnn_score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWLOWYz8J_pQ",
    "outputId": "49f125be-d2c5-44ed-bea5-5bb44ef19ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.875\n",
      "Averaged F1: 0.8771203865528938\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.88      0.82        33\n",
      "           1       0.94      0.87      0.91        71\n",
      "\n",
      "    accuracy                           0.88       104\n",
      "   macro avg       0.85      0.88      0.86       104\n",
      "weighted avg       0.88      0.88      0.88       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cnn_y_true = np.argmax(y_test,axis=1)\n",
    "cnn_pred = model.predict(x_test)\n",
    "cnn_pred = np.argmax(cnn_pred,axis=1)\n",
    "\n",
    "\n",
    "cnn_score = metrics.accuracy_score(cnn_y_true, cnn_pred)\n",
    "print('Accuracy: {}'.format(cnn_score))\n",
    "\n",
    "\n",
    "cnn_f1 = metrics.f1_score(cnn_y_true, cnn_pred, average='weighted')\n",
    "print('Averaged F1: {}'.format(cnn_f1))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(cnn_y_true, cnn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9gdCPNdN8th"
   },
   "source": [
    "## CNN Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lUhpjcrHamOx",
    "outputId": "047f08fe-0569-4c3d-db29-9431a195e9c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 1, 14, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 1, 13, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 1, 11, 64)         6208      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1000)              193000    \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 201,338\n",
      "Trainable params: 201,338\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 - 1s - loss: 0.6894 - accuracy: 0.6803 - val_loss: 0.4943 - val_accuracy: 0.7788\n",
      "Epoch 2/10\n",
      "13/13 - 0s - loss: 0.4887 - accuracy: 0.7644 - val_loss: 0.3784 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "13/13 - 0s - loss: 0.3601 - accuracy: 0.8582 - val_loss: 0.3235 - val_accuracy: 0.8558\n",
      "Epoch 4/10\n",
      "13/13 - 0s - loss: 0.2677 - accuracy: 0.9087 - val_loss: 0.3047 - val_accuracy: 0.9038\n",
      "Epoch 5/10\n",
      "13/13 - 0s - loss: 0.2431 - accuracy: 0.8918 - val_loss: 0.2991 - val_accuracy: 0.8462\n",
      "Epoch 6/10\n",
      "13/13 - 0s - loss: 0.2175 - accuracy: 0.9159 - val_loss: 0.2953 - val_accuracy: 0.8654\n",
      "Epoch 7/10\n",
      "13/13 - 0s - loss: 0.2151 - accuracy: 0.9087 - val_loss: 0.2714 - val_accuracy: 0.8846\n",
      "Epoch 8/10\n",
      "13/13 - 0s - loss: 0.1984 - accuracy: 0.9279 - val_loss: 0.3307 - val_accuracy: 0.9038\n",
      "Epoch 9/10\n",
      "13/13 - 0s - loss: 0.2093 - accuracy: 0.9111 - val_loss: 0.2775 - val_accuracy: 0.8846\n",
      "Epoch 10/10\n",
      "13/13 - 0s - loss: 0.1885 - accuracy: 0.9255 - val_loss: 0.2599 - val_accuracy: 0.8942\n",
      "\n",
      "Elapsed time: 0:00:01.89\n",
      "\n",
      "Test loss: 0.25992491841316223\n",
      "\n",
      "Test accuracy: 0.8942307829856873\n",
      "\n",
      "Averaged F1: 0.8928066186686876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83        33\n",
      "           1       0.91      0.94      0.92        71\n",
      "\n",
      "    accuracy                           0.89       104\n",
      "   macro avg       0.89      0.87      0.87       104\n",
      "weighted avg       0.89      0.89      0.89       104\n",
      "\n",
      "Accuracy: 0.8942307692307693\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(1, 3), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 1)))\n",
    "model.add(Conv2D(64, (1, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 3)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=4, verbose=2, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test), callbacks=[monitor])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"\\nElapsed time: {}\\n\".format(hms_string(elapsed_time)))\n",
    "\n",
    "cnn_score2 = model.evaluate(x_test, y_test, verbose=0)\n",
    "cnn_score2\n",
    "\n",
    "print('Test loss: {}\\n'.format(cnn_score2[0]))\n",
    "print('Test accuracy: {}'.format(cnn_score2[1]))\n",
    "\n",
    "cnn_y_true2 = np.argmax(y_test,axis=1)\n",
    "cnn_pred2 = model.predict(x_test)\n",
    "cnn_pred2 = np.argmax(cnn_pred2,axis=1)\n",
    "\n",
    "cnn_f1_2 = metrics.f1_score(cnn_y_true2, cnn_pred2, average='weighted')\n",
    "print('\\nAveraged F1: {}'.format(cnn_f1_2))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(cnn_y_true2, cnn_pred2))\n",
    "\n",
    "cnn_score2 = metrics.accuracy_score(cnn_y_true2, cnn_pred2)\n",
    "print('Accuracy: {}'.format(cnn_score2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4T-ppE7OT6Q"
   },
   "source": [
    "## CNN Model #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3lQ2uBhlOVHY",
    "outputId": "72e8ba90-c7d1-41fc-da4f-2756219f3827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 1, 15, 32)         96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 13, 64)         4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 3, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1000)              129000    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 151,770\n",
      "Trainable params: 151,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 - 1s - loss: 0.7565 - accuracy: 0.6178 - val_loss: 0.5931 - val_accuracy: 0.6827\n",
      "Epoch 2/10\n",
      "13/13 - 0s - loss: 0.6016 - accuracy: 0.6803 - val_loss: 0.4887 - val_accuracy: 0.7788\n",
      "Epoch 3/10\n",
      "13/13 - 0s - loss: 0.4824 - accuracy: 0.7909 - val_loss: 0.4910 - val_accuracy: 0.7692\n",
      "Epoch 4/10\n",
      "13/13 - 0s - loss: 0.3829 - accuracy: 0.8317 - val_loss: 0.3200 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "13/13 - 0s - loss: 0.2910 - accuracy: 0.8750 - val_loss: 0.2877 - val_accuracy: 0.8846\n",
      "Epoch 6/10\n",
      "13/13 - 0s - loss: 0.2599 - accuracy: 0.8798 - val_loss: 0.3554 - val_accuracy: 0.8654\n",
      "Epoch 7/10\n",
      "13/13 - 0s - loss: 0.2957 - accuracy: 0.8918 - val_loss: 0.3202 - val_accuracy: 0.8558\n",
      "Epoch 8/10\n",
      "13/13 - 0s - loss: 0.2455 - accuracy: 0.8942 - val_loss: 0.2549 - val_accuracy: 0.9231\n",
      "Epoch 9/10\n",
      "13/13 - 0s - loss: 0.2181 - accuracy: 0.9183 - val_loss: 0.2418 - val_accuracy: 0.9423\n",
      "Epoch 10/10\n",
      "13/13 - 0s - loss: 0.1993 - accuracy: 0.9159 - val_loss: 0.3043 - val_accuracy: 0.8558\n",
      "\n",
      "Elapsed time: 0:00:01.97\n",
      "\n",
      "Test loss: 0.304347962141037\n",
      "\n",
      "Test accuracy: 0.8557692170143127\n",
      "\n",
      "Averaged F1: 0.8600159382602132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.94      0.81        33\n",
      "           1       0.97      0.82      0.89        71\n",
      "\n",
      "    accuracy                           0.86       104\n",
      "   macro avg       0.84      0.88      0.85       104\n",
      "weighted avg       0.88      0.86      0.86       104\n",
      "\n",
      "Accuracy: 0.8557692307692307\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(1, 2), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 1)))\n",
    "model.add(Conv2D(64, (1, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 3)))\n",
    "model.add(Conv2D(128, (1, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 3)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=4, verbose=2, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test), callbacks=[monitor])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"\\nElapsed time: {}\\n\".format(hms_string(elapsed_time)))\n",
    "\n",
    "cnn_score3 = model.evaluate(x_test, y_test, verbose=0)\n",
    "cnn_score3\n",
    "\n",
    "print('Test loss: {}\\n'.format(cnn_score3[0]))\n",
    "print('Test accuracy: {}'.format(cnn_score3[1]))\n",
    "\n",
    "cnn_y_true3 = np.argmax(y_test,axis=1)\n",
    "cnn_pred3 = model.predict(x_test)\n",
    "cnn_pred3 = np.argmax(cnn_pred3,axis=1)\n",
    "\n",
    "cnn_f1_3 = metrics.f1_score(cnn_y_true3, cnn_pred3, average='weighted')\n",
    "print('\\nAveraged F1: {}'.format(cnn_f1_3))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(cnn_y_true3, cnn_pred3))\n",
    "\n",
    "cnn_score3 = metrics.accuracy_score(cnn_y_true3, cnn_pred3)\n",
    "print('Accuracy: {}'.format(cnn_score3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1_NA6HbObro"
   },
   "source": [
    "## CNN Model #4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y__2VLbBOdU7",
    "outputId": "8b4bd4fc-3a2c-4336-b6ee-cd76319045b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 1, 15, 32)         96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 1, 14, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 1, 13, 64)         4160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 1, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 1, 3, 128)         16512     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 1000)              129000    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 2)                 2002      \n",
      "=================================================================\n",
      "Total params: 151,770\n",
      "Trainable params: 151,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 - 1s - loss: 0.5641 - accuracy: 0.6947 - val_loss: 0.4665 - val_accuracy: 0.7788\n",
      "Epoch 2/10\n",
      "13/13 - 0s - loss: 0.4147 - accuracy: 0.8221 - val_loss: 0.3760 - val_accuracy: 0.8462\n",
      "Epoch 3/10\n",
      "13/13 - 0s - loss: 0.3448 - accuracy: 0.8462 - val_loss: 0.3473 - val_accuracy: 0.8558\n",
      "Epoch 4/10\n",
      "13/13 - 0s - loss: 0.3112 - accuracy: 0.8630 - val_loss: 0.3414 - val_accuracy: 0.8558\n",
      "Epoch 5/10\n",
      "13/13 - 0s - loss: 0.2621 - accuracy: 0.8966 - val_loss: 0.3126 - val_accuracy: 0.8654\n",
      "Epoch 6/10\n",
      "13/13 - 0s - loss: 0.2397 - accuracy: 0.9231 - val_loss: 0.2933 - val_accuracy: 0.8654\n",
      "Epoch 7/10\n",
      "13/13 - 0s - loss: 0.2353 - accuracy: 0.9159 - val_loss: 0.2812 - val_accuracy: 0.8942\n",
      "Epoch 8/10\n",
      "13/13 - 0s - loss: 0.2052 - accuracy: 0.9399 - val_loss: 0.2685 - val_accuracy: 0.9135\n",
      "Epoch 9/10\n",
      "13/13 - 0s - loss: 0.2014 - accuracy: 0.9231 - val_loss: 0.2909 - val_accuracy: 0.8846\n",
      "Epoch 10/10\n",
      "13/13 - 0s - loss: 0.1861 - accuracy: 0.9375 - val_loss: 0.2476 - val_accuracy: 0.9423\n",
      "\n",
      "Elapsed time: 0:00:02.08\n",
      "\n",
      "Test loss: 0.24755239486694336\n",
      "\n",
      "Test accuracy: 0.942307710647583\n",
      "\n",
      "Averaged F1: 0.9423076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        33\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.94       104\n",
      "   macro avg       0.93      0.93      0.93       104\n",
      "weighted avg       0.94      0.94      0.94       104\n",
      "\n",
      "Accuracy: 0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(1, 2), strides=(1, 1),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(1, 2), strides=(1, 1)))\n",
    "model.add(Conv2D(64, (1, 2), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 3)))\n",
    "model.add(Conv2D(128, (1, 2), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 3)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=4, verbose=2, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test), callbacks=[monitor])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"\\nElapsed time: {}\\n\".format(hms_string(elapsed_time)))\n",
    "\n",
    "cnn_score4 = model.evaluate(x_test, y_test, verbose=0)\n",
    "cnn_score4\n",
    "\n",
    "print('Test loss: {}\\n'.format(cnn_score4[0]))\n",
    "print('Test accuracy: {}'.format(cnn_score4[1]))\n",
    "\n",
    "cnn_y_true4 = np.argmax(y_test,axis=1)\n",
    "cnn_pred4 = model.predict(x_test)\n",
    "cnn_pred4 = np.argmax(cnn_pred4,axis=1)\n",
    "\n",
    "cnn_f1_4 = metrics.f1_score(cnn_y_true4, cnn_pred4, average='weighted')\n",
    "print('\\nAveraged F1: {}'.format(cnn_f1_4))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(cnn_y_true4, cnn_pred4))\n",
    "\n",
    "cnn_score4 = metrics.accuracy_score(cnn_y_true4, cnn_pred4)\n",
    "print('Accuracy: {}'.format(cnn_score4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YpnmvSCKOkAS"
   },
   "source": [
    "## CNN Model #5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBX7aO57Oo_H",
    "outputId": "c0926144-483c-41ae-d2c1-e390c43a6b73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 1, 16, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1, 16, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 1, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 8, 64)          6208      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 1, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 138,946\n",
      "Trainable params: 138,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 - 1s - loss: 1.2810 - accuracy: 0.5288 - val_loss: 0.6139 - val_accuracy: 0.6827\n",
      "Epoch 2/10\n",
      "13/13 - 0s - loss: 0.9698 - accuracy: 0.5457 - val_loss: 0.5692 - val_accuracy: 0.6827\n",
      "Epoch 3/10\n",
      "13/13 - 0s - loss: 0.7676 - accuracy: 0.6418 - val_loss: 0.5389 - val_accuracy: 0.7885\n",
      "Epoch 4/10\n",
      "13/13 - 0s - loss: 0.6837 - accuracy: 0.6322 - val_loss: 0.4979 - val_accuracy: 0.7981\n",
      "Epoch 5/10\n",
      "13/13 - 0s - loss: 0.6629 - accuracy: 0.6298 - val_loss: 0.4395 - val_accuracy: 0.8077\n",
      "Epoch 6/10\n",
      "13/13 - 0s - loss: 0.6079 - accuracy: 0.7163 - val_loss: 0.4461 - val_accuracy: 0.8365\n",
      "Epoch 7/10\n",
      "13/13 - 0s - loss: 0.5570 - accuracy: 0.7019 - val_loss: 0.3761 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "13/13 - 0s - loss: 0.4656 - accuracy: 0.7812 - val_loss: 0.3730 - val_accuracy: 0.8462\n",
      "Epoch 9/10\n",
      "13/13 - 0s - loss: 0.4586 - accuracy: 0.7692 - val_loss: 0.3508 - val_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "13/13 - 0s - loss: 0.4211 - accuracy: 0.8173 - val_loss: 0.3364 - val_accuracy: 0.8654\n",
      "\n",
      "Elapsed time: 0:00:02.08\n",
      "\n",
      "Test loss: 0.3363763689994812\n",
      "\n",
      "Test accuracy: 0.8653846383094788\n",
      "\n",
      "Averaged F1: 0.8664027149321267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.82      0.79        33\n",
      "           1       0.91      0.89      0.90        71\n",
      "\n",
      "    accuracy                           0.87       104\n",
      "   macro avg       0.84      0.85      0.85       104\n",
      "weighted avg       0.87      0.87      0.87       104\n",
      "\n",
      "Accuracy: 0.8653846153846154\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (1, 3), padding='same',\n",
    "                 input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (1, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy, optimizer=Adam(lr=0.001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=4, verbose=2, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train,     \n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test, y_test), callbacks=[monitor])\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"\\nElapsed time: {}\\n\".format(hms_string(elapsed_time)))\n",
    "\n",
    "cnn_score5 = model.evaluate(x_test, y_test, verbose=0)\n",
    "cnn_score5\n",
    "\n",
    "print('Test loss: {}\\n'.format(cnn_score5[0]))\n",
    "print('Test accuracy: {}'.format(cnn_score5[1]))\n",
    "\n",
    "cnn_y_true5 = np.argmax(y_test,axis=1)\n",
    "cnn_pred5 = model.predict(x_test)\n",
    "cnn_pred5 = np.argmax(cnn_pred5,axis=1)\n",
    "\n",
    "cnn_f1_5 = metrics.f1_score(cnn_y_true5, cnn_pred5, average='weighted')\n",
    "print('\\nAveraged F1: {}'.format(cnn_f1_5))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(cnn_y_true5, cnn_pred5))\n",
    "\n",
    "cnn_score5 = metrics.accuracy_score(cnn_y_true5, cnn_pred5)\n",
    "print('Accuracy: {}'.format(cnn_score5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7C_iCVRvOx6o"
   },
   "source": [
    "## Best Model Results for CNN (Model #4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "giBGSdiPO8lX",
    "outputId": "caec80f4-1cd8-42d1-afb6-beb12c0714c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30  3]\n",
      " [ 3 68]]\n"
     ]
    }
   ],
   "source": [
    "cm_cnn = metrics.confusion_matrix(cnn_y_true4, cnn_pred4)\n",
    "print(cm_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "ahERx8H0O_Q9",
    "outputId": "2e69a120-6d18-4218-b5ea-a19aaadb3383"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plotting confusion matrix')\n",
    "\n",
    "outcome = encode_text_index(df, 'class')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_cnn, outcome)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EUcu0s0xPS9g",
    "outputId": "c1dea46f-1ba9-4d6d-8857-1a82941259dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Averaged F1: 0.9423076923076923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        33\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.94       104\n",
      "   macro avg       0.93      0.93      0.93       104\n",
      "weighted avg       0.94      0.94      0.94       104\n",
      "\n",
      "Accuracy: 0.9423076923076923\n"
     ]
    }
   ],
   "source": [
    "cnn_f1_4 = metrics.f1_score(cnn_y_true4, cnn_pred4, average='weighted')\n",
    "print('\\nAveraged F1: {}'.format(cnn_f1_4))\n",
    "\n",
    "           \n",
    "print(metrics.classification_report(cnn_y_true4, cnn_pred4))\n",
    "\n",
    "cnn_score4 = metrics.accuracy_score(cnn_y_true4, cnn_pred4)\n",
    "print('Accuracy: {}'.format(cnn_score4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdI3CwC3kBX_"
   },
   "source": [
    "## Best Model Results for Fully Connected Neural Network Models (Model #2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgVyVw0wkFW2",
    "outputId": "20be88e8-68f5-4355-811d-9e27bbbfffad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "[[32  1]\n",
      " [ 1 70]]\n"
     ]
    }
   ],
   "source": [
    "cm_fcnn = metrics.confusion_matrix(y_true, pred2)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(cm_fcnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "Eib1tUSHkpU7",
    "outputId": "b7c86e1e-6118-402c-cca8-b3e6a710829c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Plotting confusion matrix')\n",
    "\n",
    "outcome = encode_text_index(df, 'class')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm_fcnn, outcome)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SxVGTAzlKCl",
    "outputId": "de7f9529-8bb0-45c8-e9b6-b04fcec56dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9807692307692307\n"
     ]
    }
   ],
   "source": [
    "score = metrics.accuracy_score(y_true, pred2)\n",
    "\n",
    "print(\"Accuracy score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y8R74Gggkp3J",
    "outputId": "abfd830d-33e5-4d49-c965-544606b7255b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        33\n",
      "           1       0.99      0.99      0.99        71\n",
      "\n",
      "    accuracy                           0.98       104\n",
      "   macro avg       0.98      0.98      0.98       104\n",
      "weighted avg       0.98      0.98      0.98       104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true, pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f1O2eQD_tQ3"
   },
   "source": [
    "## Results\n",
    "\n",
    "Having played around with both neural network model types and models using Random Forest, KNN, and SVM algorithms, we were able to successfully use AI to predict diabetes risk among patients using the dataset provided by the UCI Repository. The model using Random Forest was able to perform with the highest accuracy score of 99%. For our best fully connected neural network model, its accuracy score was 98% and the CNN model had 94%. In our evaluation of the performance of CNN vs. fully connected neural network models, we have determined that CNN models are the better predictor for classification between the two neural network model types. This is due to the fact that the performance of the fully connected neural network models was very inconsistent. The accuracy scores range from low 30%'s to high 60%'s with very few instances going above the upper range. On the other hand, the CNN models would consistently perform with accuracy scores sitting above 80% on all trial runs. Therefore, we consider our best fully connected neural network model to be an outlier and our CNN model to be the best predictor of the two."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CSC 180 Final Project Derek Sakasegawa Eric Wong Jack Tran.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
